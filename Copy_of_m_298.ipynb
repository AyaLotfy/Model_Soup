{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9GQR-J4ARAL",
        "outputId": "f723ff9e-3668-4554-c66a-a206dead181f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results_h = 'results_h.jsonl'\n",
        "results_t = 'results_t.jsonl'\n",
        "best_model_f = 'best_model_f.jsonl'\n"
      ],
      "metadata": {
        "id": "HyWBNiBxMvx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKZ0yTrMawyy"
      },
      "outputs": [],
      "source": [
        "!mkdir ckpts\n",
        "!mkdir reports\n",
        "!mkdir results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mck7F4eKN6iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6fbba8-9a8e-45c6-cbc6-9d9e665a57c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.23.5)\n",
            "Collecting boto3 (from pytorch_pretrained_bert)\n",
            "  Downloading boto3-1.28.68-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.66.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.1.0)\n",
            "Collecting botocore<1.32.0,>=1.31.68 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading botocore-1.31.68-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.68->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.68->boto3->pytorch_pretrained_bert) (1.16.0)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=83a3a80d377596827a8cb5b7cb1509a981d981c6823ded21b6a352f9a7907214\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, safetensors, jmespath, huggingface-hub, botocore, tokenizers, s3transfer, transformers, boto3, pytorch_pretrained_bert\n",
            "Successfully installed GPUtil-1.4.0 boto3-1.28.68 botocore-1.31.68 huggingface-hub-0.17.3 jmespath-1.0.1 pytorch_pretrained_bert-0.6.2 s3transfer-0.7.0 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
            "Collecting barbar\n",
            "  Downloading barbar-0.2.1-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: barbar\n",
            "Successfully installed barbar-0.2.1\n",
            "\u001b[33mWARNING: Skipping emoji as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting emoji==1.7\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=38e87270d33b6dcbf67d9915d615bb711b0919002c7b4f6ac1e58eef4f32363b\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n",
            "Collecting emojis\n",
            "  Downloading emojis-0.7.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: emojis\n",
            "Successfully installed emojis-0.7.0\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install GPUtil pytorch_pretrained_bert transformers\n",
        "!pip install barbar\n",
        "!pip uninstall emoji\n",
        "!pip install emoji==1.7\n",
        "!pip install emojis\n",
        "!pip install --upgrade urllib3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz5sqG5EKhsw"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from barbar import Bar\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import re\n",
        "from emoji import UNICODE_EMOJI\n",
        "import sys\n",
        "import emojis\n",
        "import numpy\n",
        "import shutil\n",
        "\n",
        "from statistics import mean\n",
        "import math\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nu1LiPIrsUt"
      },
      "outputs": [],
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "\n",
        "        self.x2h = nn.Linear(input_size, 3 * hidden_size, bias=bias)\n",
        "        self.h2h = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "\n",
        "        # Inputs:\n",
        "        #       input: of shape (batch_size, input_size)\n",
        "        #       hx: of shape (batch_size, hidden_size)\n",
        "        # Output:\n",
        "        #       hy: of shape (batch_size, hidden_size)\n",
        "\n",
        "        if hx is None:\n",
        "            hx = Variable(input.new_zeros(input.size(0), self.hidden_size))\n",
        "\n",
        "        x_t = self.x2h(input)\n",
        "        h_t = self.h2h(hx)\n",
        "\n",
        "\n",
        "        x_reset, x_upd, x_new = x_t.chunk(3, 1)\n",
        "        h_reset, h_upd, h_new = h_t.chunk(3, 1)\n",
        "\n",
        "        reset_gate = torch.sigmoid(x_reset + h_reset)\n",
        "        update_gate = torch.sigmoid(x_upd + h_upd)\n",
        "        new_gate = torch.tanh(x_new + (reset_gate * h_new))\n",
        "\n",
        "        hy = update_gate * hx + (1 - update_gate) * new_gate\n",
        "\n",
        "        return hy\n",
        "\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, bias, output_size):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bias = bias\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.rnn_cell_list = nn.ModuleList()\n",
        "\n",
        "        self.rnn_cell_list.append(GRUCell(self.input_size,\n",
        "                                          self.hidden_size,\n",
        "                                          self.bias))\n",
        "        for l in range(1, self.num_layers):\n",
        "            self.rnn_cell_list.append(GRUCell(self.hidden_size,\n",
        "                                              self.hidden_size,\n",
        "                                              self.bias))\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "\n",
        "        # Input of shape (batch_size, seqence length, input_size)\n",
        "        #\n",
        "        # Output of shape (batch_size, output_size)\n",
        "\n",
        "        if hx is None:\n",
        "            if torch.cuda.is_available():\n",
        "                h0 = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size).cuda())\n",
        "            else:\n",
        "                h0 = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size))\n",
        "\n",
        "        else:\n",
        "             h0 = hx\n",
        "\n",
        "        outs = []\n",
        "\n",
        "        hidden = list()\n",
        "        for layer in range(self.num_layers):\n",
        "            hidden.append(h0[layer, :, :])\n",
        "\n",
        "        for t in range(input.size(1)):\n",
        "\n",
        "            for layer in range(self.num_layers):\n",
        "\n",
        "                if layer == 0:\n",
        "                    hidden_l = self.rnn_cell_list[layer](input[:, t, :], hidden[layer])\n",
        "                else:\n",
        "                    hidden_l = self.rnn_cell_list[layer](hidden[layer - 1],hidden[layer])\n",
        "                hidden[layer] = hidden_l\n",
        "\n",
        "                hidden[layer] = hidden_l\n",
        "\n",
        "            outs.append(hidden_l)\n",
        "\n",
        "        # Take only last time step. Modify for seq to seq\n",
        "        out = outs[-1].squeeze()\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15fHQ5Kyc0ON"
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FADsPUQyOTQD"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, df, pretraine_path='xlm-roberta-base', max_length=128):\n",
        "        self.df = df\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(pretraine_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.df.iloc[index]['tweet']\n",
        "        label = self.df.iloc[index][\"sarcastic\"]\n",
        "\n",
        "        encoded_input = self.tokenizer(\n",
        "                text,\n",
        "                max_length = self.max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        input_ids = encoded_input[\"input_ids\"]\n",
        "        attention_mask = encoded_input[\"attention_mask\"] if \"attention_mask\" in encoded_input else None\n",
        "\n",
        "        data_input = {\n",
        "            \"input_ids\":input_ids.flatten(),\n",
        "            \"attention_mask\": attention_mask.flatten()\n",
        "        }\n",
        "\n",
        "        label_input ={\n",
        "            \"sarcasm\": torch.tensor(label, dtype=torch.float),\n",
        "        }\n",
        "\n",
        "        return data_input, label_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ob4YoaMNLq8"
      },
      "outputs": [],
      "source": [
        "def label_rule(mis_preds, cat_preds):\n",
        "    for i in range(len(mis_preds)):\n",
        "        if mis_preds[i] == 0:\n",
        "            cat_preds[i] = 0\n",
        "    return cat_preds\n",
        "\n",
        "\n",
        "def accuracy(preds, y):\n",
        "    all_output = preds.float().cpu()\n",
        "    all_label = y.float().cpu()\n",
        "    _, predict = torch.max(all_output, 1)\n",
        "    acc = accuracy_score(all_label.numpy(), torch.squeeze(predict).float().numpy())\n",
        "    return acc\n",
        "\n",
        "def calc_accuracy(preds,y):\n",
        "    predict = torch.argmax(preds, dim=1)\n",
        "    accuracy = torch.sum(predict == y.squeeze()).float().item()\n",
        "    return accuracy / float(preds.size()[0])\n",
        "\n",
        "def calc_f1_sarcasm(preds,y):\n",
        "\n",
        "    predict = torch.argmax(preds, dim=1)\n",
        "    f1_sarcastic = f1_score(y, predict, average='binary', pos_label=1)\n",
        "    return f1_sarcastic\n",
        "\n",
        "def calc_f1_score(preds,y):\n",
        "    predict = torch.argmax(preds, dim=1)\n",
        "    f1_score_macro = f1_score(y, predict, average='macro')\n",
        "    return f1_score_macro\n",
        "\n",
        "def binary_accuracy2(preds, y):\n",
        "    # round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds).squeeze()\n",
        "\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / (y.size(0))\n",
        "    return acc\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    # round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds).squeeze()\n",
        "\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / (y.size(0) * y.size(1))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnUk1BOZnkat"
      },
      "source": [
        "# preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiCkdKaannS3"
      },
      "outputs": [],
      "source": [
        "\n",
        "dic = {\n",
        "      \"egypt\": 'المصرية',\n",
        "\t  \"nile\": 'المصرية',\n",
        "\t  \"msa\": \"اللغة العربية الفصحى\",\n",
        "\t  \"magreb\": \"المغربية\",\n",
        "\t  \"gulf\": \"الخليجية\",\n",
        "\t  \"levant\": \"الشامية\"\n",
        "}\n",
        "\n",
        "def is_emoji(s):\n",
        "    return s in UNICODE_EMOJI\n",
        "\n",
        "# add space near your emoji\n",
        "def add_space(text):\n",
        "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n",
        "\n",
        "def preprocess(text):\n",
        "    sent = add_space(text)\n",
        "    sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n",
        "    sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n",
        "    sent = sent.replace('_', ' ')\n",
        "    sent = sent.replace('#', ' ')\n",
        "    return sent\n",
        "\n",
        "def prepare_text(df, col):\n",
        "    if col == 'tweet':\n",
        "        df['dialect'] = df['dialect'].map(dic)\n",
        "    for i in range(df.shape[0]):\n",
        "        df.loc[i, col] = df.loc[i, 'dialect'] + ' [SEP] ' + df.loc[i, col]\n",
        "\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadTrainValData2(size=0.2, batchsize=16, num_worker=0, pretraine_path=\"marbert\", seed=42, max_length=128):\n",
        "    path = \"/content/drive/MyDrive/iSarcasm/Datasets2/split_80_20/train.csv\"\n",
        "    data = pd.read_csv(path, encoding='utf-8')\n",
        "    data = data[~data.tweet.isna()]\n",
        "    data['tweet'] = data['tweet'].apply(lambda x: preprocess(x))\n",
        "    data = prepare_text(data, col='tweet')\n",
        "\n",
        "    rephrase_df = data[[\"rephrase\", \"dialect\"]]\n",
        "    rephrase_df = rephrase_df.dropna().reset_index(drop=True)\n",
        "    rephrase_df['rephrase'] = rephrase_df['rephrase'].apply(lambda x: preprocess(x))\n",
        "    rephrase_df = prepare_text(rephrase_df, col='rephrase')\n",
        "    rephrase_df = rephrase_df[[\"rephrase\"]]\n",
        "\n",
        "    rephrase_df[\"sarcastic\"] = 0\n",
        "    rephrase_df.columns = [\"tweet\", \"sarcastic\"]\n",
        "    data = data[[\"tweet\", \"sarcastic\"]]\n",
        "    data = data.sample(frac=1).reset_index(drop=True)\n",
        "    df_train = data\n",
        "    df_train = pd.concat([df_train, rephrase_df])\n",
        "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    path = \"/content/drive/MyDrive/iSarcasm/Datasets2/split_80_20/val.csv\"\n",
        "    data = pd.read_csv(path, encoding='utf-8')\n",
        "    data = data[~data.tweet.isna()]\n",
        "    data['tweet'] = data['tweet'].apply(lambda x: preprocess(x))\n",
        "    data = prepare_text(data, col='tweet')\n",
        "    df_test = data\n",
        "    DF_train = TrainDataset(df_train, pretraine_path, max_length)\n",
        "    DF_test = TrainDataset(df_test, pretraine_path, max_length)\n",
        "\n",
        "    DF_train_loader = DataLoader(dataset=DF_train, batch_size=batchsize, shuffle=True,\n",
        "                                 num_workers=num_worker)\n",
        "    DF_test_loader = DataLoader(dataset=DF_test, batch_size=batchsize, shuffle=False,\n",
        "                                num_workers=num_worker)\n",
        "    return DF_train_loader, DF_test_loader"
      ],
      "metadata": {
        "id": "oa_4SMQ3jPsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadTestData(batchsize=16, num_worker=2, pretraine_path=\"xlm-roberta-base\", max_length=128):\n",
        "    path = \"/content/drive/MyDrive/iSarcasm/Datasets2/tweet/task_A_Ar_test.csv\"\n",
        "    data = pd.read_csv(path, encoding='utf-8')\n",
        "    data['tweet'] = data['tweet'].apply(lambda x:preprocess(x))\n",
        "    data = prepare_text(data, col='tweet')\n",
        "\n",
        "    DF_test = TrainDataset(data, pretraine_path, max_length)\n",
        "\n",
        "    DF_test_loader = DataLoader(dataset=DF_test, batch_size=batchsize, shuffle=False,\n",
        "                                num_workers=num_worker)\n",
        "\n",
        "\n",
        "    return DF_test_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "-6tnueS6JUWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A8SY0Un6gbS"
      },
      "source": [
        "# Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr2rYqyv6i4F"
      },
      "outputs": [],
      "source": [
        "class FocalLoss_Ori(nn.Module):\n",
        "    \"\"\"\n",
        "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
        "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
        "    Focal_Loss= -1*alpha*((1-pt)**gamma)*log(pt)\n",
        "    Args:\n",
        "        num_class: number of classes\n",
        "        alpha: class balance factor\n",
        "        gamma:\n",
        "        ignore_index:\n",
        "        reduction:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_class, alpha=None, gamma=2, ignore_index=None, reduction='mean'):\n",
        "        super(FocalLoss_Ori, self).__init__()\n",
        "        self.num_class = num_class\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.smooth = 1e-4\n",
        "        self.ignore_index = ignore_index\n",
        "        self.alpha = alpha\n",
        "        if alpha is None:\n",
        "            self.alpha = torch.ones(num_class, )\n",
        "        elif isinstance(alpha, (int, float)):\n",
        "            self.alpha = torch.as_tensor([alpha] * num_class)\n",
        "        elif isinstance(alpha, (list, np.ndarray)):\n",
        "            self.alpha = torch.as_tensor(alpha)\n",
        "        if self.alpha.shape[0] != num_class:\n",
        "            raise RuntimeError('the length not equal to number of class')\n",
        "\n",
        "    def forward(self, logit, target):\n",
        "        # assert isinstance(self.alpha,torch.Tensor)\\\n",
        "        N, C = logit.shape[:2]\n",
        "        alpha = self.alpha.to(logit.device)\n",
        "        prob = F.softmax(logit, dim=1)\n",
        "        if prob.dim() > 2:\n",
        "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
        "            prob = prob.view(N, C, -1)\n",
        "            prob = prob.transpose(1, 2).contiguous()  # [N,C,d1*d2..] -> [N,d1*d2..,C]\n",
        "            prob = prob.view(-1, prob.size(-1))  # [N,d1*d2..,C]-> [N*d1*d2..,C]\n",
        "        ori_shp = target.shape\n",
        "        target = target.view(-1, 1)  # [N,d1,d2,...]->[N*d1*d2*...,1]\n",
        "        valid_mask = None\n",
        "        if self.ignore_index is not None:\n",
        "            valid_mask = target != self.ignore_index\n",
        "            target = target * valid_mask\n",
        "\n",
        "        # ----------memory saving way--------\n",
        "        prob = prob.gather(1, target).view(-1) + self.smooth  # avoid nan\n",
        "        logpt = torch.log(prob)\n",
        "        # alpha_class = alpha.gather(0, target.view(-1))\n",
        "        alpha_class = alpha[target.squeeze().long()]\n",
        "        class_weight = -alpha_class * torch.pow(torch.sub(1.0, prob), self.gamma)\n",
        "        loss = class_weight * logpt\n",
        "        if valid_mask is not None:\n",
        "            loss = loss * valid_mask.squeeze()\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "            if valid_mask is not None:\n",
        "                loss = loss.sum() / valid_mask.sum()\n",
        "\n",
        "        elif self.reduction == 'none':\n",
        "            loss = loss.view(ori_shp)\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4HVgjBd4eP"
      },
      "source": [
        "# modeling 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5UrAuWXd7yW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def init_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1 or classname.find('ConvTranspose2d') != -1:\n",
        "        nn.init.kaiming_uniform_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self,both=True,\n",
        "                pretrained_path='aubmindlab/bert-base-arabert'):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "\n",
        "        self.both = both\n",
        "        self.transformer = AutoModel.from_pretrained(pretrained_path, output_hidden_states=True)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None):\n",
        "        outputs = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        # (output_last_layer, pooled_cls, (output_layers))\n",
        "        # output[0] (8, seqlen=64, 768) cls [8, 768] ( 12 (8, seqlen=64, 768))\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def output_num(self):\n",
        "        return self.transformer.config.hidden_size\n",
        "\n",
        "class ATTClassifier(nn.Module):\n",
        "    def __init__(self, in_feature, class_num=1, dropout_prob=0.2):\n",
        "        super(ATTClassifier, self).__init__()\n",
        "        self.model = GRU(input_size=in_feature, hidden_size=in_feature, num_layers=1, bias=True , output_size=in_feature)\n",
        "\n",
        "        self.Classifier = nn.Sequential(\n",
        "            nn.Linear(2 * in_feature, 512),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, class_num)\n",
        "        )\n",
        "\n",
        "        self.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        mod = self.model(x[0]) #(X[0] (bs, seqlenght, embedD) att = \\sum_i alpha_i x[0][i]\n",
        "        xx = torch.cat([mod, x[1]], 1)\n",
        "\n",
        "        out = self.Classifier(xx)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWb2TiUoQO-x"
      },
      "source": [
        "# train_sarcat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1-oxBZ-ZSfA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def train(base_model, mt_classifier, iterator, optimizer, sar_criterion, scheduler):\n",
        "\n",
        "    # set the model in eval phase\n",
        "    base_model.train(True)\n",
        "    mt_classifier.train(True)\n",
        "\n",
        "    acc_sarcasm= 0\n",
        "    f1_sarcasm =0\n",
        "    f1_score_macro = 0\n",
        "    loss_sarc= 0\n",
        "\n",
        "    all_sarcasm_outputs = np.array([])\n",
        "    all_sarcasm_labels = np.array([])\n",
        "\n",
        "    for data_input, label_input  in Bar(iterator):\n",
        "\n",
        "        for k, v in data_input.items():\n",
        "            data_input[k] = v.to(device)\n",
        "\n",
        "        for k, v in label_input.items():\n",
        "            label_input[k] = v.long().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        #forward pass\n",
        "\n",
        "        sarcasm_target = label_input['sarcasm']\n",
        "\n",
        "        # forward pass\n",
        "\n",
        "        output = base_model(**data_input)\n",
        "        sarcasm_logits = mt_classifier(output)\n",
        "\n",
        "        sarcasm_probs = torch.softmax(sarcasm_logits, dim=1)\n",
        "\n",
        "        loss_sarcasm = sar_criterion(sarcasm_logits, sarcasm_target)\n",
        "        loss_sarc += loss_sarcasm.item()\n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss_sarcasm.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        acc_sarcasm += calc_accuracy(sarcasm_probs, sarcasm_target)\n",
        "        _, predicted_sarcasm = torch.max(sarcasm_probs, 1)\n",
        "        all_sarcasm_outputs = np.append(all_sarcasm_outputs, predicted_sarcasm.squeeze().cpu().numpy())\n",
        "        all_sarcasm_labels = np.append(all_sarcasm_labels, sarcasm_target.squeeze().cpu().numpy())\n",
        "\n",
        "    all_sarcasm_outputs = all_sarcasm_outputs.reshape(-1)\n",
        "    all_sarcasm_labels = all_sarcasm_labels.reshape(-1)\n",
        "\n",
        "    fscore_macro = f1_score(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs, average='macro')\n",
        "    fscore_sarcasm = f1_score(all_sarcasm_labels, all_sarcasm_outputs, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "    accuracies = { 'accuracy': acc_sarcasm / len(iterator), 'f1_sarcastic': fscore_sarcasm, \"f1_score\": fscore_macro}\n",
        "    losses = { 'loss': loss_sarc / len(iterator)}\n",
        "    return accuracies, losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFJSkOVlZW2y"
      },
      "outputs": [],
      "source": [
        "def evaluate(base_model, mt_classifier, iterator, sar_criterion):\n",
        "    # initialize every epoch\n",
        "    acc_sarcasm= 0\n",
        "    f1_sarcasm =0\n",
        "    f1_score_macro = 0\n",
        "    loss_sarc= 0\n",
        "\n",
        "    #all_sarcasm_outputs = []\n",
        "    all_sarcasm_outputs = np.array([])\n",
        "    all_sarcasm_labels = np.array([])\n",
        "\n",
        "    # set the model in eval phase\n",
        "    base_model.eval()\n",
        "    mt_classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        for data_input, label_input in Bar(iterator):\n",
        "\n",
        "            for k, v in data_input.items():\n",
        "                data_input[k] = v.to(device)\n",
        "\n",
        "            for k, v in label_input.items():\n",
        "                label_input[k] = v.long().to(device)\n",
        "\n",
        "\n",
        "            sarcasm_target = label_input['sarcasm']\n",
        "\n",
        "            # forward pass\n",
        "\n",
        "            output = base_model(**data_input)\n",
        "            sarcasm_logits = mt_classifier(output)\n",
        "            logits = sarcasm_logits[:,:2]\n",
        "\n",
        "            sarcasm_probs = torch.softmax(logits, dim=1)\n",
        "            # compute the loss\n",
        "            loss_sarcasm = sar_criterion(logits, sarcasm_target)\n",
        "\n",
        "            # compute the running accuracy and losses\n",
        "            acc_sarcasm += calc_accuracy(sarcasm_probs, sarcasm_target)\n",
        "            loss_sarc += loss_sarcasm.item()\n",
        "\n",
        "            _, predicted_sarcasm = torch.max(sarcasm_probs, 1)\n",
        "            #all_sarcasm_outputs.extend(predicted_sarcasm.squeeze().int().cpu().numpy().tolist())\n",
        "            all_sarcasm_outputs = np.append(all_sarcasm_outputs, predicted_sarcasm.squeeze().cpu().numpy())\n",
        "            #all_sarcasm_labels.extend(sarcasm_target.squeeze().int().cpu().numpy().tolist())\n",
        "            all_sarcasm_labels = np.append(all_sarcasm_labels, sarcasm_target.squeeze().cpu().numpy())\n",
        "    all_sarcasm_outputs = all_sarcasm_outputs.reshape(-1)\n",
        "    all_sarcasm_labels = all_sarcasm_labels.reshape(-1)\n",
        "\n",
        "    fscore_macro = f1_score(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs, average='macro')\n",
        "    fscore_sarcasm = f1_score(all_sarcasm_labels, all_sarcasm_outputs, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "    report_sarcasm = classification_report(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs,digits=4)\n",
        "\n",
        "\n",
        "    accuracies = { 'accuracy': acc_sarcasm / len(iterator), 'f1_sarcastic': fscore_sarcasm, \"f1_score\": fscore_macro, 'report_sarcasm': report_sarcasm}\n",
        "    losses = { 'loss': loss_sarc / len(iterator)}\n",
        "    return accuracies, losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf-lgC1LZcGu"
      },
      "outputs": [],
      "source": [
        "def predict(base_model, mt_classifier, iterator):\n",
        "    # initialize every epoch\n",
        "    acc_sarcasm= 0\n",
        "    loss_sarc= 0\n",
        "\n",
        "    f1_sarcasm =0\n",
        "    f1_score_macro = 0\n",
        "\n",
        "    #all_sarcasm_outputs = []\n",
        "    all_sarcasm_outputs = np.array([])\n",
        "    all_sarcasm_labels = np.array([])\n",
        "\n",
        "    # set the model in eval phase\n",
        "    base_model.eval()\n",
        "    mt_classifier.eval()\n",
        "    with torch.no_grad():\n",
        "      for data_input, label_input in Bar(iterator):\n",
        "            for k, v in data_input.items():\n",
        "                data_input[k] = v.to(device)\n",
        "\n",
        "            for k, v in label_input.items():\n",
        "                label_input[k] = v.long().to(device)\n",
        "\n",
        "            sarcasm_target = label_input['sarcasm']\n",
        "\n",
        "            # forward pass\n",
        "\n",
        "            output = base_model(**data_input)\n",
        "            sarcasm_logits = mt_classifier(output)\n",
        "            logits = sarcasm_logits[:,:2]\n",
        "            sarcasm_probs = torch.softmax(logits, dim=1)\n",
        "            # compute the loss\n",
        "            acc_sarcasm += calc_accuracy(sarcasm_probs, sarcasm_target)\n",
        "\n",
        "            _, predicted_sarcasm = torch.max(sarcasm_probs, 1)\n",
        "            #all_sarcasm_outputs.extend(predicted_sarcasm.squeeze().int().cpu().numpy().tolist())\n",
        "            all_sarcasm_outputs = np.append(all_sarcasm_outputs, predicted_sarcasm.squeeze().cpu().numpy())\n",
        "            all_sarcasm_labels = np.append(all_sarcasm_labels, sarcasm_target.squeeze().cpu().numpy())\n",
        "\n",
        "    all_sarcasm_outputs = all_sarcasm_outputs.reshape(-1)\n",
        "    all_sarcasm_labels = all_sarcasm_labels.reshape(-1)\n",
        "    fscore_macro = f1_score(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs, average='macro')\n",
        "    fscore_sarcasm = f1_score(all_sarcasm_labels, all_sarcasm_outputs, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "    report_sarcasm = classification_report(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs,digits=4)\n",
        "\n",
        "\n",
        "    accuracies = { 'accuracy': acc_sarcasm / len(iterator), 'f1_sarcastic': fscore_sarcasm, \"f1_score\": fscore_macro, 'report_sarcasm': report_sarcasm}\n",
        "    return accuracies, all_sarcasm_outputs, all_sarcasm_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YDenIrPUIvrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBM3sBfzZl4c"
      },
      "outputs": [],
      "source": [
        "def eval_full(config, loader1):\n",
        "    criterion = config['loss']\n",
        "    base_model = TransformerLayer(pretrained_path=config['pretrained_path'], both=True).to(device)\n",
        "    classifier = ATTClassifier(base_model.output_num(), class_num=2).to(device)\n",
        "    base_model.load_state_dict(torch.load(f\"./ckpts/best_basemodel_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\"))\n",
        "    classifier.load_state_dict(torch.load(f\"./ckpts/best_cls_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\"))\n",
        "    base_model = base_model.to(device)\n",
        "    classifier = classifier.to(device)\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    accuracies, all_outputs_pred, all_outputs_label = predict(base_model, classifier, loader1)\n",
        "    return accuracies, all_outputs_pred, all_outputs_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnYj2EAOZte_"
      },
      "outputs": [],
      "source": [
        "def plot_cf(cf_matrix):\n",
        "    ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "    ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "    ax.set_xlabel('\\nPredicted Values')\n",
        "    ax.set_ylabel('Actual Values ');\n",
        "    ## Ticket labels - List must be in alphabetical order\n",
        "    ax.xaxis.set_ticklabels(['False','True'])\n",
        "    ax.yaxis.set_ticklabels(['False','True'])\n",
        "    ## Display the visualization of the Confusion Matrix.\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "pS3ZHef_3-if",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba24217-3e8d-4b07-e7bd-47d8aaadb568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mckpts\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34mreports\u001b[0m/  \u001b[01;34mresults\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lr_arr = [1e-5,2e-5]\n",
        "# batch_arr = [16,32,36,64]\n",
        "# epoch_arr = [2,4]\n",
        "# loss_arr=['FL']\n",
        "# seed_arr=[298]"
      ],
      "metadata": {
        "id": "gHDHjV_d25sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir '/content/drive/MyDrive/iSarcasm/m_298'"
      ],
      "metadata": {
        "id": "B5evIk3J8FS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d23e65-b927-49aa-9a95-0cb1b331fd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/iSarcasm/m_298’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_i =298\n",
        "epoch_i=2\n",
        "lr_i =2e-5\n",
        "loss_i = 'FL'\n",
        "batch_i = 16"
      ],
      "metadata": {
        "id": "qlf-oc4RVTkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {}\n",
        "args['lr_mult'] = 1.0\n",
        "args['seed'] = seed_i\n",
        "args['num_worker'] = 4\n",
        "args['lang'] = 'ar'\n",
        "args['phase'] = 'train'\n",
        "args['lm_pretrained'] = 'marbert'\n",
        "\n",
        "args['lr'] =lr_i\n",
        "args['epochs'] = epoch_i\n",
        "args['batch_size'] = batch_i\n",
        "args['loss'] = loss_i\n",
        "config = {}\n",
        "config[\"max_length\"] = 64\n",
        "config['args'] = args\n",
        "config[\"output_for_test\"] = True\n",
        "config['epochs'] = args['epochs']\n",
        "config[\"class_num\"] = 1\n",
        "config[\"lr\"] = args['lr']\n",
        "config['lr_mult'] = args['lr_mult']\n",
        "config['batch_size'] = args['batch_size']\n",
        "config['lm'] = args['lm_pretrained']\n",
        "config['loss'] = args['loss']\n",
        "lang = args['lang']\n",
        "dosegmentation = False\n",
        "\n",
        "\n",
        "if args['lm_pretrained'] == 'marbert':\n",
        "    config['pretrained_path'] = \"UBC-NLP/MARBERT\""
      ],
      "metadata": {
        "id": "gfa2aN1BVk4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = config['args']['seed']\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "Qhw2TR2yVvUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = f\"{config['args']['batch_size']}_{config['args']['loss']}_{config['args']['lr']}_{config['args']['epochs']}_{config['args']['seed']}\"\n",
        "print('model_name', model_name)\n",
        "train_loader, valid_loader = loadTrainValData2(size = 0.2 ,batchsize=args['batch_size'], num_worker=0, pretraine_path=config['pretrained_path'], max_length=config['max_length'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "0ff16adf91434118982a81e4aac97cfb",
            "765eece32f2c4e949e79d50a803898a0",
            "c4ebf49aa19e4e7ba649010f08ccec57",
            "e5f5bacea13b4ae9b7b2fb232d04d2df",
            "b5e559995762472c98042d27be0686c8",
            "cce47a824497445eab88eeb56fc4c362",
            "9ff28ca54338484eb36344e4f023d55f",
            "1ee316331bc54e72a3f68df278001596",
            "275c484b8b5a42aab37f15682d56c445",
            "a44534b56c37482e9f9d0dc35e7f1bdf",
            "361335aea1bd429db6fd36a702f8412e",
            "7cb347dc1f28433fbe9e637de608f344",
            "3f13939a54f14843a62cb2f0b2875f69",
            "89eba0976309418ba24a7dc3d8d67a3c",
            "c9f4cda1d802441fa6aa4f2a69979f95",
            "7a6908225bf0460182ba5de15335ca2f",
            "b8e2b0b01da64b438d333d2cc868d1bc",
            "7efee491d1da4a9783ea07e3fe3d3bd2",
            "6bc094bb736944af9e349cf78a9005ae",
            "a8c736dfc43e44638f4c6d160fb81639",
            "59081e8c5df9481295cea2d1db032b85",
            "ecaaa7c5899443ca972ae9c7c91e2c40",
            "5b07fa6c873b4c2591bf23b1e8379db5",
            "0510f9a30b5145a1ba2f63d2cf42a206",
            "acb835349d724eefad534871baac4772",
            "563902de5e1a4d768b5f9b28707cfe47",
            "995ee0522d574631b57eb43ba0f66d70",
            "96f15955f9474f179e1a80ed13ff11e5",
            "2cebd98ab9604639b0d84ce1e1bd5c40",
            "1ee3701c69f244db99ef9ddc433b32b1",
            "071f63c81d0c4bf1b7359ad2a2e2252a",
            "ed9af588295e433cbf26c1bc115647a0",
            "9c893d1cd0994e9e9bf370688cc1f334",
            "85e80bdadf7f40d5bd0a4cc5619fbfff",
            "eca6f447f3f84fa480dc355041fce014",
            "75a1fa4d668b454682438bbaf20ad58a",
            "ed117ed0fb18428189e62cbf59cd6441",
            "0cbe1c7139f14663bfd3eae1dbf73df2",
            "675c81626c0d409cbd263481ca32f08e",
            "66948be883874e4ba49df70d3c36ac41",
            "d366c645e7174f9198dd6b8dabb74b4e",
            "788ff67f3c654913ab3a5de738943009",
            "93549ae235f14c6cbe609eb364178abf",
            "a92c221fa2c9436bb31b96c08351a9bd"
          ]
        },
        "id": "HODLDF_CV37E",
        "outputId": "a2d50f41-2d9e-4bc9-ff97-cad102b641f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name 16_FL_2e-05_2_298\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ff16adf91434118982a81e4aac97cfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cb347dc1f28433fbe9e637de608f344"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b07fa6c873b4c2591bf23b1e8379db5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85e80bdadf7f40d5bd0a4cc5619fbfff"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_accuracy, best_val_f1_score, best_val_f1_sarcastic, best_val_loss, best_epo =train_full(config, train_loader, valid_loader)\n"
      ],
      "metadata": {
        "id": "RZlBBL29WOIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stest_loader = valid_loader"
      ],
      "metadata": {
        "id": "jGMJlPNNWP7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_o = config['lr_mult'] * config['lr']\n",
        "lr = config['lr']\n",
        "criterion = config['loss']\n",
        "#Instanciate models\n",
        "base_model = TransformerLayer(pretrained_path=config['pretrained_path'], both=True).to(device)\n",
        "mtl_classifier = ATTClassifier(base_model.output_num(), class_num=2).to(device)\n",
        "cls = 'ATTClassifier'\n",
        "\n",
        "if criterion =='FL':\n",
        "    sarc_criterion = FocalLoss_Ori(num_class=2, alpha=[1, 1], gamma=2).to(device)\n",
        "else:\n",
        "    sarc_criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "89e40573c95e4445beab9b79ad99a2f0",
            "9bb82e2ac44b4450be3d04bdb153b518",
            "3ee913dd6c0c4fdcab281743cc2061b4",
            "7e5773ab470f46be8d559fec77f5226d",
            "b302589729f5455496f5691406cd2197",
            "271413dc3a514e488ebd69fb52f6536b",
            "3e95dfaca3ac4697bd30c63ec7733674",
            "eb1c1aa011e7477abca1c1e59f37103f",
            "955afdd71658406694e36174f72e7b6c",
            "02341d00c0a142caa4444d4c0c9ee1a1",
            "e02e58cce63f49e09a0fe222f8c02c01"
          ]
        },
        "id": "mqcz9m2xWf5B",
        "outputId": "2faa2fd7-4d21-4837-a512-423f32c4f9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89e40573c95e4445beab9b79ad99a2f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = [{'params':base_model.parameters(), 'lr':config['lr']}, {'params': mtl_classifier.parameters(), 'lr': config['lr']}]#, {'params':multi_task_loss.parameters(), 'lr': 0.0005}]\n",
        "optimizer = AdamW(params, lr=config[\"lr\"])\n",
        "\n",
        "train_data_size = len(train_loader)\n",
        "steps_per_epoch = int(train_data_size / config['batch_size'])\n",
        "num_train_steps = len(train_loader) * config['epochs']\n",
        "warmup_steps = int(config['epochs'] * train_data_size * 0.1 / config['batch_size'])\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,  num_warmup_steps=warmup_steps, num_training_steps=num_train_steps)\n",
        "# Train model\n",
        "\n",
        "best_val_accuracy = 0\n",
        "best_val_f1_score = 0\n",
        "best_val_f1_sarcastic = 0\n",
        "\n",
        "best_val_metric = 0\n",
        "\n",
        "best_val_loss = float('+inf')\n",
        "\n",
        "best_report_sarcasm = None\n",
        "\n",
        "epo = 0"
      ],
      "metadata": {
        "id": "uTazIH6QWqig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_accuracies, valid_losses = evaluate(base_model, mtl_classifier, valid_loader, sarc_criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEO6hnn3XIq2",
        "outputId": "c0794994-ca16-48ca-9758-bf99f1f57676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "621/621: [===============================>] - ETA 3.9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWzI1d5LXVM6",
        "outputId": "e8bbe4ad-4451-4033-ad64-de22ec6e7d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7581360946745562,\n",
              " 'f1_sarcastic': 0.0,\n",
              " 'f1_score': 0.4313186813186813,\n",
              " 'report_sarcasm': '              precision    recall  f1-score   support\\n\\n         0.0     0.7597    0.9979    0.8626       472\\n         1.0     0.0000    0.0000    0.0000       149\\n\\n    accuracy                         0.7585       621\\n   macro avg     0.3798    0.4989    0.4313       621\\nweighted avg     0.5774    0.7585    0.6557       621\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uMFYH7UXYoG",
        "outputId": "02809cec-442c-4f83-8c82-f393b9ba3720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.14235295546360505}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WokMh3BrWDCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "results = {'model_name' : f'initial_model_h'}\n",
        "\n",
        "results['f1_sarcastic'] = valid_accuracies['f1_sarcastic']\n",
        "results['f1_score'] = valid_accuracies['f1_score']\n",
        "\n",
        "\n",
        "\n",
        "with open(results_h, 'a+') as f:\n",
        "      f.write(json.dumps(results) + '\\n')"
      ],
      "metadata": {
        "id": "7sqyjproV8F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = loadTestData(batchsize=args['batch_size'], num_worker=0, pretraine_path=config['pretrained_path'],  max_length=config['max_length'])\n"
      ],
      "metadata": {
        "id": "BJuFJ0jwY3zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "test_accuracies, test_all_outputs, test_all_labels = eval_full(config, loader1=test_loader,base_model, classif)"
      ],
      "metadata": {
        "id": "36OJbtJ8YPh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = test_loader"
      ],
      "metadata": {
        "id": "Ugrz3PaSY9Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize every epoch\n",
        "acc_sarcasm= 0\n",
        "f1_sarcasm =0\n",
        "f1_score_macro = 0\n",
        "loss_sarc= 0\n",
        "\n",
        "#all_sarcasm_outputs = []\n",
        "all_sarcasm_outputs = np.array([])\n",
        "all_sarcasm_labels = np.array([])\n",
        "\n",
        "# set the model in eval phase\n",
        "base_model.eval()\n",
        "mtl_classifier.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NarsEzhUZCk2",
        "outputId": "971697d3-b781-459e-e206-9e40b8a56350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ATTClassifier(\n",
              "  (model): GRU(\n",
              "    (rnn_cell_list): ModuleList(\n",
              "      (0): GRUCell(\n",
              "        (x2h): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (h2h): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (Classifier): Sequential(\n",
              "    (0): Linear(in_features=1536, out_features=512, bias=True)\n",
              "    (1): Dropout(p=0.2, inplace=False)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for data_input, label_input in Bar(iterator):\n",
        "\n",
        "        for k, v in data_input.items():\n",
        "            data_input[k] = v.to(device)\n",
        "\n",
        "        for k, v in label_input.items():\n",
        "            label_input[k] = v.long().to(device)\n",
        "\n",
        "\n",
        "        sarcasm_target = label_input['sarcasm']\n",
        "\n",
        "        # forward pass\n",
        "\n",
        "        output = base_model(**data_input)\n",
        "        sarcasm_logits = mtl_classifier(output)\n",
        "        logits = sarcasm_logits[:,:2]\n",
        "\n",
        "        sarcasm_probs = torch.softmax(logits, dim=1)\n",
        "        # compute the loss\n",
        "        # loss_sarcasm = sar_criterion(logits, sarcasm_target)\n",
        "\n",
        "        # compute the running accuracy and losses\n",
        "        acc_sarcasm += calc_accuracy(sarcasm_probs, sarcasm_target)\n",
        "        # loss_sarc += loss_sarcasm.item()\n",
        "\n",
        "        _, predicted_sarcasm = torch.max(sarcasm_probs, 1)\n",
        "        #all_sarcasm_outputs.extend(predicted_sarcasm.squeeze().int().cpu().numpy().tolist())\n",
        "        all_sarcasm_outputs = np.append(all_sarcasm_outputs, predicted_sarcasm.squeeze().cpu().numpy())\n",
        "        #all_sarcasm_labels.extend(sarcasm_target.squeeze().int().cpu().numpy().tolist())\n",
        "        all_sarcasm_labels = np.append(all_sarcasm_labels, sarcasm_target.squeeze().cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J86xtPmCZSXX",
        "outputId": "f959162f-7115-4c9c-8510-f8e3df92fbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400/1400: [===============================>] - ETA 0.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_sarcasm_outputs = all_sarcasm_outputs.reshape(-1)\n",
        "all_sarcasm_labels = all_sarcasm_labels.reshape(-1)\n",
        "\n",
        "fscore_macro = f1_score(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs, average='macro')\n",
        "fscore_sarcasm = f1_score(all_sarcasm_labels, all_sarcasm_outputs, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "report_sarcasm = classification_report(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs,digits=4)"
      ],
      "metadata": {
        "id": "iW-zdBFYZloz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = { 'accuracy': acc_sarcasm / len(iterator), 'f1_sarcastic': fscore_sarcasm, \"f1_score\": fscore_macro, 'report_sarcasm': report_sarcasm}\n"
      ],
      "metadata": {
        "id": "dOmvytGSZoFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4nBuMNLY0Qn",
        "outputId": "18aa3775-7b93-4e90-db8f-bad653dea09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8579545454545454,\n",
              " 'f1_sarcastic': 0.009950248756218907,\n",
              " 'f1_score': 0.46669116901066043,\n",
              " 'report_sarcasm': '              precision    recall  f1-score   support\\n\\n         0.0     0.8578    1.0000    0.9234      1200\\n         1.0     1.0000    0.0050    0.0100       200\\n\\n    accuracy                         0.8579      1400\\n   macro avg     0.9289    0.5025    0.4667      1400\\nweighted avg     0.8781    0.8579    0.7929      1400\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies['report_sarcasm']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ohW8G6Q0aIeT",
        "outputId": "609131bc-15e6-44ef-d867-108864085b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n         0.0     0.8578    1.0000    0.9234      1200\\n         1.0     1.0000    0.0050    0.0100       200\\n\\n    accuracy                         0.8579      1400\\n   macro avg     0.9289    0.5025    0.4667      1400\\nweighted avg     0.8781    0.8579    0.7929      1400\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies['report_sarcasm'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_ewlTVPNaTa2",
        "outputId": "ea520330-8e65-4ace-b61e-3bcf44d9106d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = {'model_name' : f'initial_model_t'}\n",
        "results['f1_sarcastic'] = accuracies['f1_sarcastic']\n",
        "results['f1_score'] = accuracies['f1_score']\n",
        "\n",
        "with open(results_t, 'a+') as f:\n",
        "      f.write(json.dumps(results) + '\\n')"
      ],
      "metadata": {
        "id": "q5s2_TepaAtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_db_h = pd.read_json(results_h, lines=True)\n",
        "print(\"results_db_h\", results_db_h)"
      ],
      "metadata": {
        "id": "psKTD5MklW7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c8bd49-6615-4532-f992-d0909c55bea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results_db_h         model_name  f1_sarcastic  f1_score\n",
            "0  initial_model_h             0  0.431319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_db_t = pd.read_json(results_t, lines=True)\n",
        "print(\"results_db_t\", results_db_t)"
      ],
      "metadata": {
        "id": "wL78BfKURMOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d603c808-aced-4f0b-eb1a-d35f59293259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results_db_t         model_name  f1_sarcastic  f1_score\n",
            "0  initial_model_t       0.00995  0.466691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/drive/MyDrive/iSarcasm/m_298/results'"
      ],
      "metadata": {
        "id": "xYKLemhDerFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"results_h.jsonl\", \"/content/drive/MyDrive/iSarcasm/m_298/results/results_h.jsonl\")\n",
        "shutil.copy(\"results_t.jsonl\", \"/content/drive/MyDrive/iSarcasm/m_298/results/results_t.jsonl\")\n",
        "# shutil.copy(\"best_model_f.jsonl\", \"/content/drive/MyDrive/iSarcasm/m_298/results/best_model_f.jsonl\")"
      ],
      "metadata": {
        "id": "ZXLV_a8QYZW_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8193b019-0015-4ab1-d9b2-0bce29f8bb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/iSarcasm/m_298/results/best_model_f.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator"
      ],
      "metadata": {
        "id": "eu5UPvVS6xQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_h = '/content/drive/MyDrive/iSarcasm/m_298/results/results_h.jsonl'\n",
        "results_t = '/content/drive/MyDrive/iSarcasm/m_298/results/results_t.jsonl'\n",
        "best_model_f = \"/content/drive/MyDrive/iSarcasm/m_298/results/best_model_f.jsonl\"\n",
        "\n",
        "if os.path.exists(best_model_f):\n",
        "    os.remove(best_model_f)\n",
        "\n",
        "results_db_h = pd.read_json(results_h, lines=True)\n",
        "results_db_t = pd.read_json(results_t, lines=True)\n",
        "\n",
        "individual_model_val_accs_h = {}\n",
        "for _, row in results_db_h.iterrows():\n",
        "    individual_model_val_accs_h[row['model_name']] = row['f1_score']\n",
        "\n",
        "individual_model_val_accs_h = sorted(individual_model_val_accs_h.items(), key=operator.itemgetter(1))\n",
        "individual_model_val_accs_h.reverse()\n",
        "sorted_models = [x[0] for x in individual_model_val_accs_h]\n",
        "\n",
        "\n",
        "\n",
        "for _, row in results_db_t.iterrows():\n",
        "    if row['model_name'] == sorted_models[0]:\n",
        "       row_t = row\n",
        "       break\n",
        "\n",
        "results = {'best_model' : f'{sorted_models[0]}'}\n",
        "\n",
        "results['loss_fn']= row_t['loss_fn']\n",
        "results['batch_size']=row_t['batch_size']\n",
        "results['lr']=row_t['lr']\n",
        "results['epoch']=row_t['epoch']\n",
        "results['seed']=row_t['seed']\n",
        "results['f1_sarcastic'] = row_t['f1_sarcastic']\n",
        "results['f1_score'] = row_t['f1_score']\n",
        "\n",
        "with open(best_model_f, 'a+') as f:\n",
        "         f.write(json.dumps(results) + '\\n')\n"
      ],
      "metadata": {
        "id": "qHoyDlknz1Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_db_t = pd.read_json(best_model_f, lines=True)\n",
        "print(\"best_model_db_t\", best_model_db_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7Cs-O9f5jEg",
        "outputId": "7ebdfe59-faac-4191-9e3c-c1f7032ac62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_db_t           best_model   loss_fn  batch_size       lr  epoch  seed  \\\n",
            "0  36_FL_2e-05_4_298  0.648526          36  0.00002      4   298   \n",
            "\n",
            "   f1_sarcastic  f1_score  \n",
            "0      0.648526   0.79141  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdGS1mxLdyhW",
        "outputId": "1b938461-cd29-4ff7-dabb-7d819cd67c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mckpts\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34mreports\u001b[0m/  \u001b[01;34mresults\u001b[0m/  results_h.jsonl  results_t.jsonl  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"results_h.jsonl\", \"/content/drive/MyDrive/iSarcasm/gru/m_298/results_i/initial_model_h.jsonl\")\n",
        "shutil.copy(\"results_t.jsonl\", \"/content/drive/MyDrive/iSarcasm/gru/m_298/results_i/initial_model_t.jsonl\")"
      ],
      "metadata": {
        "id": "guJiGSoy6_tY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7849b1e2-d3c7-4b7f-8bc4-cd59872a0b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/iSarcasm/gru/m_298/results_i/initial_model_t.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/drive/MyDrive/iSarcasm/gru/m_298/results_i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn19Ww9sd6JU",
        "outputId": "f970d386-b6f1-446a-a0aa-7beac8c0eabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_f10.jsonl            greedy_soup_results_h.jsonl  results_h9.jsonl\n",
            "best_model_f11.jsonl            greedy_soup_results_t.jsonl  results_t10.jsonl\n",
            "best_model_f12.jsonl            initial_model_h.jsonl        results_t11.jsonl\n",
            "best_model_f13.jsonl            initial_model_t.jsonl        results_t12.jsonl\n",
            "best_model_f14.jsonl            results_h10.jsonl            results_t13.jsonl\n",
            "best_model_f15.jsonl            results_h11.jsonl            results_t14.jsonl\n",
            "best_model_f16.jsonl            results_h12.jsonl            results_t15.jsonl\n",
            "best_model_f1.jsonl             results_h13.jsonl            results_t16.jsonl\n",
            "best_model_f2.jsonl             results_h14.jsonl            results_t1.jsonl\n",
            "best_model_f3.jsonl             results_h15.jsonl            results_t2.jsonl\n",
            "best_model_f4.jsonl             results_h16.jsonl            results_t3.jsonl\n",
            "best_model_f5.jsonl             results_h1.jsonl             results_t4.jsonl\n",
            "best_model_f6.jsonl             results_h2.jsonl             results_t5.jsonl\n",
            "best_model_f7.jsonl             results_h3.jsonl             results_t6.jsonl\n",
            "best_model_f8.jsonl             results_h4.jsonl             results_t7.jsonl\n",
            "best_model_f9.jsonl             results_h5.jsonl             results_t8.jsonl\n",
            "best_model_f_all.jsonl          results_h6.jsonl             results_t9.jsonl\n",
            "ensemble_model_results_t.jsonl  results_h7.jsonl             uniform_soup_results_h.jsonl\n",
            "figure_n_models_gru_t.png       results_h8.jsonl             uniform_soup_results_t.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVBWgVvxeGzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ff16adf91434118982a81e4aac97cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_765eece32f2c4e949e79d50a803898a0",
              "IPY_MODEL_c4ebf49aa19e4e7ba649010f08ccec57",
              "IPY_MODEL_e5f5bacea13b4ae9b7b2fb232d04d2df"
            ],
            "layout": "IPY_MODEL_b5e559995762472c98042d27be0686c8"
          }
        },
        "765eece32f2c4e949e79d50a803898a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce47a824497445eab88eeb56fc4c362",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff28ca54338484eb36344e4f023d55f",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "c4ebf49aa19e4e7ba649010f08ccec57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee316331bc54e72a3f68df278001596",
            "max": 376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_275c484b8b5a42aab37f15682d56c445",
            "value": 376
          }
        },
        "e5f5bacea13b4ae9b7b2fb232d04d2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a44534b56c37482e9f9d0dc35e7f1bdf",
            "placeholder": "​",
            "style": "IPY_MODEL_361335aea1bd429db6fd36a702f8412e",
            "value": " 376/376 [00:00&lt;00:00, 4.04kB/s]"
          }
        },
        "b5e559995762472c98042d27be0686c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce47a824497445eab88eeb56fc4c362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff28ca54338484eb36344e4f023d55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ee316331bc54e72a3f68df278001596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "275c484b8b5a42aab37f15682d56c445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a44534b56c37482e9f9d0dc35e7f1bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361335aea1bd429db6fd36a702f8412e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cb347dc1f28433fbe9e637de608f344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f13939a54f14843a62cb2f0b2875f69",
              "IPY_MODEL_89eba0976309418ba24a7dc3d8d67a3c",
              "IPY_MODEL_c9f4cda1d802441fa6aa4f2a69979f95"
            ],
            "layout": "IPY_MODEL_7a6908225bf0460182ba5de15335ca2f"
          }
        },
        "3f13939a54f14843a62cb2f0b2875f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e2b0b01da64b438d333d2cc868d1bc",
            "placeholder": "​",
            "style": "IPY_MODEL_7efee491d1da4a9783ea07e3fe3d3bd2",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "89eba0976309418ba24a7dc3d8d67a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc094bb736944af9e349cf78a9005ae",
            "max": 701,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8c736dfc43e44638f4c6d160fb81639",
            "value": 701
          }
        },
        "c9f4cda1d802441fa6aa4f2a69979f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59081e8c5df9481295cea2d1db032b85",
            "placeholder": "​",
            "style": "IPY_MODEL_ecaaa7c5899443ca972ae9c7c91e2c40",
            "value": " 701/701 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "7a6908225bf0460182ba5de15335ca2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e2b0b01da64b438d333d2cc868d1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efee491d1da4a9783ea07e3fe3d3bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bc094bb736944af9e349cf78a9005ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c736dfc43e44638f4c6d160fb81639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59081e8c5df9481295cea2d1db032b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecaaa7c5899443ca972ae9c7c91e2c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b07fa6c873b4c2591bf23b1e8379db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0510f9a30b5145a1ba2f63d2cf42a206",
              "IPY_MODEL_acb835349d724eefad534871baac4772",
              "IPY_MODEL_563902de5e1a4d768b5f9b28707cfe47"
            ],
            "layout": "IPY_MODEL_995ee0522d574631b57eb43ba0f66d70"
          }
        },
        "0510f9a30b5145a1ba2f63d2cf42a206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f15955f9474f179e1a80ed13ff11e5",
            "placeholder": "​",
            "style": "IPY_MODEL_2cebd98ab9604639b0d84ce1e1bd5c40",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "acb835349d724eefad534871baac4772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee3701c69f244db99ef9ddc433b32b1",
            "max": 1099714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_071f63c81d0c4bf1b7359ad2a2e2252a",
            "value": 1099714
          }
        },
        "563902de5e1a4d768b5f9b28707cfe47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9af588295e433cbf26c1bc115647a0",
            "placeholder": "​",
            "style": "IPY_MODEL_9c893d1cd0994e9e9bf370688cc1f334",
            "value": " 1.10M/1.10M [00:00&lt;00:00, 4.24MB/s]"
          }
        },
        "995ee0522d574631b57eb43ba0f66d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f15955f9474f179e1a80ed13ff11e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cebd98ab9604639b0d84ce1e1bd5c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ee3701c69f244db99ef9ddc433b32b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071f63c81d0c4bf1b7359ad2a2e2252a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9af588295e433cbf26c1bc115647a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c893d1cd0994e9e9bf370688cc1f334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e80bdadf7f40d5bd0a4cc5619fbfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eca6f447f3f84fa480dc355041fce014",
              "IPY_MODEL_75a1fa4d668b454682438bbaf20ad58a",
              "IPY_MODEL_ed117ed0fb18428189e62cbf59cd6441"
            ],
            "layout": "IPY_MODEL_0cbe1c7139f14663bfd3eae1dbf73df2"
          }
        },
        "eca6f447f3f84fa480dc355041fce014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675c81626c0d409cbd263481ca32f08e",
            "placeholder": "​",
            "style": "IPY_MODEL_66948be883874e4ba49df70d3c36ac41",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "75a1fa4d668b454682438bbaf20ad58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d366c645e7174f9198dd6b8dabb74b4e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_788ff67f3c654913ab3a5de738943009",
            "value": 112
          }
        },
        "ed117ed0fb18428189e62cbf59cd6441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93549ae235f14c6cbe609eb364178abf",
            "placeholder": "​",
            "style": "IPY_MODEL_a92c221fa2c9436bb31b96c08351a9bd",
            "value": " 112/112 [00:00&lt;00:00, 1.65kB/s]"
          }
        },
        "0cbe1c7139f14663bfd3eae1dbf73df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675c81626c0d409cbd263481ca32f08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66948be883874e4ba49df70d3c36ac41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d366c645e7174f9198dd6b8dabb74b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788ff67f3c654913ab3a5de738943009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93549ae235f14c6cbe609eb364178abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92c221fa2c9436bb31b96c08351a9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e40573c95e4445beab9b79ad99a2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bb82e2ac44b4450be3d04bdb153b518",
              "IPY_MODEL_3ee913dd6c0c4fdcab281743cc2061b4",
              "IPY_MODEL_7e5773ab470f46be8d559fec77f5226d"
            ],
            "layout": "IPY_MODEL_b302589729f5455496f5691406cd2197"
          }
        },
        "9bb82e2ac44b4450be3d04bdb153b518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_271413dc3a514e488ebd69fb52f6536b",
            "placeholder": "​",
            "style": "IPY_MODEL_3e95dfaca3ac4697bd30c63ec7733674",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "3ee913dd6c0c4fdcab281743cc2061b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb1c1aa011e7477abca1c1e59f37103f",
            "max": 654186400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_955afdd71658406694e36174f72e7b6c",
            "value": 654186400
          }
        },
        "7e5773ab470f46be8d559fec77f5226d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02341d00c0a142caa4444d4c0c9ee1a1",
            "placeholder": "​",
            "style": "IPY_MODEL_e02e58cce63f49e09a0fe222f8c02c01",
            "value": " 654M/654M [00:05&lt;00:00, 134MB/s]"
          }
        },
        "b302589729f5455496f5691406cd2197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271413dc3a514e488ebd69fb52f6536b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e95dfaca3ac4697bd30c63ec7733674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb1c1aa011e7477abca1c1e59f37103f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955afdd71658406694e36174f72e7b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02341d00c0a142caa4444d4c0c9ee1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02e58cce63f49e09a0fe222f8c02c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}