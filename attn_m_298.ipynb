{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9GQR-J4ARAL",
        "outputId": "fac40c61-d687-486d-9466-81503110ca6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results_h = 'results_h.jsonl'\n",
        "results_t = 'results_t.jsonl'\n",
        "best_model_f = 'best_model_f.jsonl'\n"
      ],
      "metadata": {
        "id": "HyWBNiBxMvx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKZ0yTrMawyy"
      },
      "outputs": [],
      "source": [
        "!mkdir ckpts\n",
        "!mkdir reports\n",
        "!mkdir results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mck7F4eKN6iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee2c3c2-99d6-4f96-9645-2f20066c30da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.23.5)\n",
            "Collecting boto3 (from pytorch_pretrained_bert)\n",
            "  Downloading boto3-1.28.68-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.66.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.1.0)\n",
            "Collecting botocore<1.32.0,>=1.31.68 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading botocore-1.31.68-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->pytorch_pretrained_bert)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.68->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.68->boto3->pytorch_pretrained_bert) (1.16.0)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=c1a0e9e082e05ae6775a4d1db4695a76195e5ef20aea022e6a6de7b34bf436d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, safetensors, jmespath, huggingface-hub, botocore, tokenizers, s3transfer, transformers, boto3, pytorch_pretrained_bert\n",
            "Successfully installed GPUtil-1.4.0 boto3-1.28.68 botocore-1.31.68 huggingface-hub-0.17.3 jmespath-1.0.1 pytorch_pretrained_bert-0.6.2 s3transfer-0.7.0 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
            "Collecting barbar\n",
            "  Downloading barbar-0.2.1-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: barbar\n",
            "Successfully installed barbar-0.2.1\n",
            "\u001b[33mWARNING: Skipping emoji as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting emoji==1.7\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=84e37952725453b2c5bb85c63134d1e755d73547e0b31a41d7eeaa1c079b0ab5\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n",
            "Collecting emojis\n",
            "  Downloading emojis-0.7.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: emojis\n",
            "Successfully installed emojis-0.7.0\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install GPUtil pytorch_pretrained_bert transformers\n",
        "!pip install barbar\n",
        "!pip uninstall emoji\n",
        "!pip install emoji==1.7\n",
        "!pip install emojis\n",
        "!pip install --upgrade urllib3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz5sqG5EKhsw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from barbar import Bar\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import re\n",
        "from emoji import UNICODE_EMOJI\n",
        "import sys\n",
        "import emojis\n",
        "import numpy\n",
        "import shutil\n",
        "\n",
        "from statistics import mean\n",
        "import math\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nu1LiPIrsUt"
      },
      "outputs": [],
      "source": [
        "class AttentionWithContext(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(AttentionWithContext, self).__init__()\n",
        "\n",
        "        self.attn = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.contx = nn.Linear(hidden_dim, 1, bias=False)\n",
        "        #self.apply(init_weights)\n",
        "    def forward(self, inp):\n",
        "        u = torch.tanh_(self.attn(inp))\n",
        "        a = F.softmax(self.contx(u), dim=1)\n",
        "        s = (a * inp).sum(1)\n",
        "        return s\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15fHQ5Kyc0ON"
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FADsPUQyOTQD"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, df, pretraine_path='xlm-roberta-base', max_length=128):\n",
        "        self.df = df\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(pretraine_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.df.iloc[index]['tweet']\n",
        "        label = self.df.iloc[index][\"sarcastic\"]\n",
        "\n",
        "        encoded_input = self.tokenizer(\n",
        "                text,\n",
        "                max_length = self.max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        input_ids = encoded_input[\"input_ids\"]\n",
        "        attention_mask = encoded_input[\"attention_mask\"] if \"attention_mask\" in encoded_input else None\n",
        "\n",
        "        data_input = {\n",
        "            \"input_ids\":input_ids.flatten(),\n",
        "            \"attention_mask\": attention_mask.flatten()\n",
        "        }\n",
        "\n",
        "        label_input ={\n",
        "            \"sarcasm\": torch.tensor(label, dtype=torch.float),\n",
        "        }\n",
        "\n",
        "        return data_input, label_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ob4YoaMNLq8"
      },
      "outputs": [],
      "source": [
        "def label_rule(mis_preds, cat_preds):\n",
        "    for i in range(len(mis_preds)):\n",
        "        if mis_preds[i] == 0:\n",
        "            cat_preds[i] = 0\n",
        "    return cat_preds\n",
        "\n",
        "\n",
        "def accuracy(preds, y):\n",
        "    all_output = preds.float().cpu()\n",
        "    all_label = y.float().cpu()\n",
        "    _, predict = torch.max(all_output, 1)\n",
        "    acc = accuracy_score(all_label.numpy(), torch.squeeze(predict).float().numpy())\n",
        "    return acc\n",
        "\n",
        "def calc_accuracy(preds,y):\n",
        "    predict = torch.argmax(preds, dim=1)\n",
        "    accuracy = torch.sum(predict == y.squeeze()).float().item()\n",
        "    return accuracy / float(preds.size()[0])\n",
        "\n",
        "def calc_f1_sarcasm(preds,y):\n",
        "\n",
        "    predict = torch.argmax(preds, dim=1)\n",
        "    f1_sarcastic = f1_score(y, predict, average='binary', pos_label=1)\n",
        "    return f1_sarcastic\n",
        "\n",
        "def calc_f1_score(preds,y):\n",
        "    predict = torch.argmax(preds, dim=1)\n",
        "    f1_score_macro = f1_score(y, predict, average='macro')\n",
        "    return f1_score_macro\n",
        "\n",
        "def binary_accuracy2(preds, y):\n",
        "    # round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds).squeeze()\n",
        "\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / (y.size(0))\n",
        "    return acc\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    # round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds).squeeze()\n",
        "\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / (y.size(0) * y.size(1))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnUk1BOZnkat"
      },
      "source": [
        "# preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiCkdKaannS3"
      },
      "outputs": [],
      "source": [
        "\n",
        "dic = {\n",
        "      \"egypt\": 'المصرية',\n",
        "\t  \"nile\": 'المصرية',\n",
        "\t  \"msa\": \"اللغة العربية الفصحى\",\n",
        "\t  \"magreb\": \"المغربية\",\n",
        "\t  \"gulf\": \"الخليجية\",\n",
        "\t  \"levant\": \"الشامية\"\n",
        "}\n",
        "\n",
        "def is_emoji(s):\n",
        "    return s in UNICODE_EMOJI\n",
        "\n",
        "# add space near your emoji\n",
        "def add_space(text):\n",
        "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n",
        "\n",
        "def preprocess(text):\n",
        "    sent = add_space(text)\n",
        "    sent = re.sub(r'(?:@[\\w_]+)', \"user\", sent)\n",
        "    sent = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', \"url\", sent)\n",
        "    sent = sent.replace('_', ' ')\n",
        "    sent = sent.replace('#', ' ')\n",
        "    return sent\n",
        "\n",
        "def prepare_text(df, col):\n",
        "    if col == 'tweet':\n",
        "        df['dialect'] = df['dialect'].map(dic)\n",
        "    for i in range(df.shape[0]):\n",
        "        df.loc[i, col] = df.loc[i, 'dialect'] + ' [SEP] ' + df.loc[i, col]\n",
        "\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadTrainValData2(size=0.2, batchsize=16, num_worker=0, pretraine_path=\"marbert\", seed=42, max_length=128):\n",
        "    path = \"/content/drive/MyDrive/iSarcasm/Datasets2/split_80_20/train.csv\"\n",
        "    data = pd.read_csv(path, encoding='utf-8')\n",
        "    data = data[~data.tweet.isna()]\n",
        "    data['tweet'] = data['tweet'].apply(lambda x: preprocess(x))\n",
        "    data = prepare_text(data, col='tweet')\n",
        "\n",
        "    rephrase_df = data[[\"rephrase\", \"dialect\"]]\n",
        "    rephrase_df = rephrase_df.dropna().reset_index(drop=True)\n",
        "    rephrase_df['rephrase'] = rephrase_df['rephrase'].apply(lambda x: preprocess(x))\n",
        "    rephrase_df = prepare_text(rephrase_df, col='rephrase')\n",
        "    rephrase_df = rephrase_df[[\"rephrase\"]]\n",
        "\n",
        "    rephrase_df[\"sarcastic\"] = 0\n",
        "    rephrase_df.columns = [\"tweet\", \"sarcastic\"]\n",
        "    data = data[[\"tweet\", \"sarcastic\"]]\n",
        "    data = data.sample(frac=1).reset_index(drop=True)\n",
        "    df_train = data\n",
        "    df_train = pd.concat([df_train, rephrase_df])\n",
        "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    path = \"/content/drive/MyDrive/iSarcasm/Datasets2/split_80_20/val.csv\"\n",
        "    data = pd.read_csv(path, encoding='utf-8')\n",
        "    data = data[~data.tweet.isna()]\n",
        "    data['tweet'] = data['tweet'].apply(lambda x: preprocess(x))\n",
        "    data = prepare_text(data, col='tweet')\n",
        "    df_test = data\n",
        "    DF_train = TrainDataset(df_train, pretraine_path, max_length)\n",
        "    DF_test = TrainDataset(df_test, pretraine_path, max_length)\n",
        "\n",
        "    DF_train_loader = DataLoader(dataset=DF_train, batch_size=batchsize, shuffle=True,\n",
        "                                 num_workers=num_worker)\n",
        "    DF_test_loader = DataLoader(dataset=DF_test, batch_size=batchsize, shuffle=False,\n",
        "                                num_workers=num_worker)\n",
        "    return DF_train_loader, DF_test_loader"
      ],
      "metadata": {
        "id": "oa_4SMQ3jPsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadTestData(batchsize=16, num_worker=2, pretraine_path=\"xlm-roberta-base\", max_length=128):\n",
        "    path = \"/content/drive/MyDrive/iSarcasm/Datasets2/tweet/task_A_Ar_test.csv\"\n",
        "    data = pd.read_csv(path, encoding='utf-8')\n",
        "    data['tweet'] = data['tweet'].apply(lambda x:preprocess(x))\n",
        "    data = prepare_text(data, col='tweet')\n",
        "\n",
        "    DF_test = TrainDataset(data, pretraine_path, max_length)\n",
        "\n",
        "    DF_test_loader = DataLoader(dataset=DF_test, batch_size=batchsize, shuffle=False,\n",
        "                                num_workers=num_worker)\n",
        "\n",
        "\n",
        "    return DF_test_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "-6tnueS6JUWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A8SY0Un6gbS"
      },
      "source": [
        "# Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr2rYqyv6i4F"
      },
      "outputs": [],
      "source": [
        "class FocalLoss_Ori(nn.Module):\n",
        "    \"\"\"\n",
        "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
        "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
        "    Focal_Loss= -1*alpha*((1-pt)**gamma)*log(pt)\n",
        "    Args:\n",
        "        num_class: number of classes\n",
        "        alpha: class balance factor\n",
        "        gamma:\n",
        "        ignore_index:\n",
        "        reduction:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_class, alpha=None, gamma=2, ignore_index=None, reduction='mean'):\n",
        "        super(FocalLoss_Ori, self).__init__()\n",
        "        self.num_class = num_class\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.smooth = 1e-4\n",
        "        self.ignore_index = ignore_index\n",
        "        self.alpha = alpha\n",
        "        if alpha is None:\n",
        "            self.alpha = torch.ones(num_class, )\n",
        "        elif isinstance(alpha, (int, float)):\n",
        "            self.alpha = torch.as_tensor([alpha] * num_class)\n",
        "        elif isinstance(alpha, (list, np.ndarray)):\n",
        "            self.alpha = torch.as_tensor(alpha)\n",
        "        if self.alpha.shape[0] != num_class:\n",
        "            raise RuntimeError('the length not equal to number of class')\n",
        "\n",
        "    def forward(self, logit, target):\n",
        "        # assert isinstance(self.alpha,torch.Tensor)\\\n",
        "        N, C = logit.shape[:2]\n",
        "        alpha = self.alpha.to(logit.device)\n",
        "        prob = F.softmax(logit, dim=1)\n",
        "        if prob.dim() > 2:\n",
        "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
        "            prob = prob.view(N, C, -1)\n",
        "            prob = prob.transpose(1, 2).contiguous()  # [N,C,d1*d2..] -> [N,d1*d2..,C]\n",
        "            prob = prob.view(-1, prob.size(-1))  # [N,d1*d2..,C]-> [N*d1*d2..,C]\n",
        "        ori_shp = target.shape\n",
        "        target = target.view(-1, 1)  # [N,d1,d2,...]->[N*d1*d2*...,1]\n",
        "        valid_mask = None\n",
        "        if self.ignore_index is not None:\n",
        "            valid_mask = target != self.ignore_index\n",
        "            target = target * valid_mask\n",
        "\n",
        "        # ----------memory saving way--------\n",
        "        prob = prob.gather(1, target).view(-1) + self.smooth  # avoid nan\n",
        "        logpt = torch.log(prob)\n",
        "        # alpha_class = alpha.gather(0, target.view(-1))\n",
        "        alpha_class = alpha[target.squeeze().long()]\n",
        "        class_weight = -alpha_class * torch.pow(torch.sub(1.0, prob), self.gamma)\n",
        "        loss = class_weight * logpt\n",
        "        if valid_mask is not None:\n",
        "            loss = loss * valid_mask.squeeze()\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "            if valid_mask is not None:\n",
        "                loss = loss.sum() / valid_mask.sum()\n",
        "\n",
        "        elif self.reduction == 'none':\n",
        "            loss = loss.view(ori_shp)\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4HVgjBd4eP"
      },
      "source": [
        "# modeling 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1 or classname.find('ConvTranspose2d') != -1:\n",
        "        nn.init.kaiming_uniform_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self,both=True,\n",
        "                pretrained_path='aubmindlab/bert-base-arabert'):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "\n",
        "        self.both = both\n",
        "        self.transformer = AutoModel.from_pretrained(pretrained_path, output_hidden_states=True)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None):\n",
        "        outputs = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        # (output_last_layer, pooled_cls, (output_layers))\n",
        "        # output[0] (8, seqlen=64, 768) cls [8, 768] ( 12 (8, seqlen=64, 768))\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def output_num(self):\n",
        "        return self.transformer.config.hidden_size"
      ],
      "metadata": {
        "id": "AFE2fW8GGlsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5UrAuWXd7yW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class ATTClassifier(nn.Module):\n",
        "    def __init__(self, in_feature, class_num=1, dropout_prob=0.2):\n",
        "        super(ATTClassifier, self).__init__()\n",
        "        self.model =  AttentionWithContext(in_feature)\n",
        "\n",
        "        self.Classifier = nn.Sequential(\n",
        "            nn.Linear(2 * in_feature, 512),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, class_num)\n",
        "        )\n",
        "\n",
        "        self.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        mod = self.model(x[0]) #(X[0] (bs, seqlenght, embedD) att = \\sum_i alpha_i x[0][i]\n",
        "        xx = torch.cat([mod, x[1]], 1)\n",
        "\n",
        "        out = self.Classifier(xx)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWb2TiUoQO-x"
      },
      "source": [
        "# train_sarcat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1-oxBZ-ZSfA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def train(base_model, mt_classifier, iterator, optimizer, sar_criterion, scheduler):\n",
        "\n",
        "    # set the model in eval phase\n",
        "    base_model.train(True)\n",
        "    mt_classifier.train(True)\n",
        "\n",
        "    acc_sarcasm= 0\n",
        "    f1_sarcasm =0\n",
        "    f1_score_macro = 0\n",
        "    loss_sarc= 0\n",
        "\n",
        "    all_sarcasm_outputs = np.array([])\n",
        "    all_sarcasm_labels = np.array([])\n",
        "\n",
        "    for data_input, label_input  in Bar(iterator):\n",
        "\n",
        "        for k, v in data_input.items():\n",
        "            data_input[k] = v.to(device)\n",
        "\n",
        "        for k, v in label_input.items():\n",
        "            label_input[k] = v.long().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        #forward pass\n",
        "\n",
        "        sarcasm_target = label_input['sarcasm']\n",
        "\n",
        "        # forward pass\n",
        "\n",
        "        output = base_model(**data_input)\n",
        "        sarcasm_logits = mt_classifier(output)\n",
        "\n",
        "        sarcasm_probs = torch.softmax(sarcasm_logits, dim=1)\n",
        "\n",
        "        loss_sarcasm = sar_criterion(sarcasm_logits, sarcasm_target)\n",
        "        loss_sarc += loss_sarcasm.item()\n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss_sarcasm.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        acc_sarcasm += calc_accuracy(sarcasm_probs, sarcasm_target)\n",
        "        _, predicted_sarcasm = torch.max(sarcasm_probs, 1)\n",
        "        all_sarcasm_outputs = np.append(all_sarcasm_outputs, predicted_sarcasm.squeeze().cpu().numpy())\n",
        "        all_sarcasm_labels = np.append(all_sarcasm_labels, sarcasm_target.squeeze().cpu().numpy())\n",
        "\n",
        "    all_sarcasm_outputs = all_sarcasm_outputs.reshape(-1)\n",
        "    all_sarcasm_labels = all_sarcasm_labels.reshape(-1)\n",
        "\n",
        "    fscore_macro = f1_score(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs, average='macro')\n",
        "    fscore_sarcasm = f1_score(all_sarcasm_labels, all_sarcasm_outputs, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "    accuracies = { 'accuracy': acc_sarcasm / len(iterator), 'f1_sarcastic': fscore_sarcasm, \"f1_score\": fscore_macro}\n",
        "    losses = { 'loss': loss_sarc / len(iterator)}\n",
        "    return accuracies, losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFJSkOVlZW2y"
      },
      "outputs": [],
      "source": [
        "def evaluate(base_model, mt_classifier, iterator, sar_criterion):\n",
        "    # initialize every epoch\n",
        "    acc_sarcasm= 0\n",
        "    f1_sarcasm =0\n",
        "    f1_score_macro = 0\n",
        "    loss_sarc= 0\n",
        "\n",
        "    #all_sarcasm_outputs = []\n",
        "    all_sarcasm_outputs = np.array([])\n",
        "    all_sarcasm_labels = np.array([])\n",
        "\n",
        "    # set the model in eval phase\n",
        "    base_model.eval()\n",
        "    mt_classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        for data_input, label_input in Bar(iterator):\n",
        "\n",
        "            for k, v in data_input.items():\n",
        "                data_input[k] = v.to(device)\n",
        "\n",
        "            for k, v in label_input.items():\n",
        "                label_input[k] = v.long().to(device)\n",
        "\n",
        "\n",
        "            sarcasm_target = label_input['sarcasm']\n",
        "\n",
        "            # forward pass\n",
        "\n",
        "            output = base_model(**data_input)\n",
        "            sarcasm_logits = mt_classifier(output)\n",
        "            logits = sarcasm_logits[:,:2]\n",
        "\n",
        "            sarcasm_probs = torch.softmax(logits, dim=1)\n",
        "            # compute the loss\n",
        "            loss_sarcasm = sar_criterion(logits, sarcasm_target)\n",
        "\n",
        "            # compute the running accuracy and losses\n",
        "            acc_sarcasm += calc_accuracy(sarcasm_probs, sarcasm_target)\n",
        "            loss_sarc += loss_sarcasm.item()\n",
        "\n",
        "            _, predicted_sarcasm = torch.max(sarcasm_probs, 1)\n",
        "            #all_sarcasm_outputs.extend(predicted_sarcasm.squeeze().int().cpu().numpy().tolist())\n",
        "            all_sarcasm_outputs = np.append(all_sarcasm_outputs, predicted_sarcasm.squeeze().cpu().numpy())\n",
        "            #all_sarcasm_labels.extend(sarcasm_target.squeeze().int().cpu().numpy().tolist())\n",
        "            all_sarcasm_labels = np.append(all_sarcasm_labels, sarcasm_target.squeeze().cpu().numpy())\n",
        "    all_sarcasm_outputs = all_sarcasm_outputs.reshape(-1)\n",
        "    all_sarcasm_labels = all_sarcasm_labels.reshape(-1)\n",
        "\n",
        "    fscore_macro = f1_score(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs, average='macro')\n",
        "    fscore_sarcasm = f1_score(all_sarcasm_labels, all_sarcasm_outputs, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "    report_sarcasm = classification_report(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs,digits=4)\n",
        "\n",
        "\n",
        "    accuracies = { 'accuracy': acc_sarcasm / len(iterator), 'f1_sarcastic': fscore_sarcasm, \"f1_score\": fscore_macro, 'report_sarcasm': report_sarcasm}\n",
        "    losses = { 'loss': loss_sarc / len(iterator)}\n",
        "    return accuracies, losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf-lgC1LZcGu"
      },
      "outputs": [],
      "source": [
        "def predict(base_model, mt_classifier, iterator):\n",
        "    # initialize every epoch\n",
        "    acc_sarcasm= 0\n",
        "    loss_sarc= 0\n",
        "\n",
        "    f1_sarcasm =0\n",
        "    f1_score_macro = 0\n",
        "\n",
        "    #all_sarcasm_outputs = []\n",
        "    all_sarcasm_outputs = np.array([])\n",
        "    all_sarcasm_labels = np.array([])\n",
        "\n",
        "    # set the model in eval phase\n",
        "    base_model.eval()\n",
        "    mt_classifier.eval()\n",
        "    with torch.no_grad():\n",
        "      for data_input, label_input in Bar(iterator):\n",
        "            for k, v in data_input.items():\n",
        "                data_input[k] = v.to(device)\n",
        "\n",
        "            for k, v in label_input.items():\n",
        "                label_input[k] = v.long().to(device)\n",
        "\n",
        "            sarcasm_target = label_input['sarcasm']\n",
        "\n",
        "            # forward pass\n",
        "\n",
        "            output = base_model(**data_input)\n",
        "            sarcasm_logits = mt_classifier(output)\n",
        "            logits = sarcasm_logits[:,:2]\n",
        "            sarcasm_probs = torch.softmax(logits, dim=1)\n",
        "            # compute the loss\n",
        "            acc_sarcasm += calc_accuracy(sarcasm_probs, sarcasm_target)\n",
        "\n",
        "            _, predicted_sarcasm = torch.max(sarcasm_probs, 1)\n",
        "            #all_sarcasm_outputs.extend(predicted_sarcasm.squeeze().int().cpu().numpy().tolist())\n",
        "            all_sarcasm_outputs = np.append(all_sarcasm_outputs, predicted_sarcasm.squeeze().cpu().numpy())\n",
        "            all_sarcasm_labels = np.append(all_sarcasm_labels, sarcasm_target.squeeze().cpu().numpy())\n",
        "\n",
        "    all_sarcasm_outputs = all_sarcasm_outputs.reshape(-1)\n",
        "    all_sarcasm_labels = all_sarcasm_labels.reshape(-1)\n",
        "    fscore_macro = f1_score(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs, average='macro')\n",
        "    fscore_sarcasm = f1_score(all_sarcasm_labels, all_sarcasm_outputs, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "    report_sarcasm = classification_report(y_true=all_sarcasm_labels, y_pred=all_sarcasm_outputs,digits=4)\n",
        "\n",
        "\n",
        "    accuracies = { 'accuracy': acc_sarcasm / len(iterator), 'f1_sarcastic': fscore_sarcasm, \"f1_score\": fscore_macro, 'report_sarcasm': report_sarcasm}\n",
        "    return accuracies, all_sarcasm_outputs, all_sarcasm_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_full(config, train_loader, stest_loader):\n",
        "    lr_o = config['lr_mult'] * config['lr']\n",
        "    lr = config['lr']\n",
        "    criterion = config['loss']\n",
        "    #Instanciate models\n",
        "    base_model = TransformerLayer(pretrained_path=config['pretrained_path'], both=True).to(device)\n",
        "    mtl_classifier = ATTClassifier(base_model.output_num(), class_num=2).to(device)\n",
        "    cls = 'ATTClassifier'\n",
        "\n",
        "    if criterion =='FL':\n",
        "        sarc_criterion = FocalLoss_Ori(num_class=2, alpha=[1, 1], gamma=2).to(device)\n",
        "    else:\n",
        "        sarc_criterion = nn.CrossEntropyLoss().to(device)\n",
        "    #\n",
        "\n",
        "    params = [{'params':base_model.parameters(), 'lr':config['lr']}, {'params': mtl_classifier.parameters(), 'lr': config['lr']}]#, {'params':multi_task_loss.parameters(), 'lr': 0.0005}]\n",
        "    optimizer = AdamW(params, lr=config[\"lr\"])\n",
        "\n",
        "    train_data_size = len(train_loader)\n",
        "    steps_per_epoch = int(train_data_size / config['batch_size'])\n",
        "    num_train_steps = len(train_loader) * config['epochs']\n",
        "    warmup_steps = int(config['epochs'] * train_data_size * 0.1 / config['batch_size'])\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,  num_warmup_steps=warmup_steps, num_training_steps=num_train_steps)\n",
        "    # Train model\n",
        "\n",
        "    best_val_accuracy = 0\n",
        "    best_val_f1_score = 0\n",
        "    best_val_f1_sarcastic = 0\n",
        "\n",
        "    best_val_metric = 0\n",
        "\n",
        "    best_val_loss = float('+inf')\n",
        "\n",
        "    best_report_sarcasm = None\n",
        "\n",
        "    epo = 0\n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        # print(\"epoch {}\".format(epoch + 1))\n",
        "\n",
        "        train_accuracies, train_losses = train(base_model, mtl_classifier, train_loader, optimizer, sarc_criterion,scheduler)\n",
        "        valid_accuracies, valid_losses = evaluate(base_model, mtl_classifier, valid_loader, sarc_criterion)\n",
        "        val_loss = valid_losses['loss']\n",
        "        total_val_metric = valid_accuracies['f1_score']\n",
        "        if epoch == (config['epochs'] - 1):\n",
        "\n",
        "            epo = epoch+1\n",
        "            best_val_loss = val_loss\n",
        "            best_val_metric = total_val_metric\n",
        "\n",
        "            best_val_f1_score = valid_accuracies['f1_score']\n",
        "            best_val_f1_sarcastic = valid_accuracies['f1_sarcastic']\n",
        "            best_report_sarcasm = valid_accuracies['report_sarcasm']\n",
        "            best_val_accuracy= valid_accuracies['accuracy']\n",
        "            best_val_loss = valid_losses['loss']\n",
        "\n",
        "            print(\"save model's checkpoint\")\n",
        "            torch.save(base_model.state_dict(), f\"./ckpts/best_basemodel_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\")\n",
        "            torch.save(mtl_classifier.state_dict(), f\"./ckpts/best_cls_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\")\n",
        "\n",
        "    return best_val_accuracy, best_val_f1_score, best_val_f1_sarcastic, best_val_loss, epo"
      ],
      "metadata": {
        "id": "YDenIrPUIvrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBM3sBfzZl4c"
      },
      "outputs": [],
      "source": [
        "def eval_full(config, loader1):\n",
        "    criterion = config['loss']\n",
        "    base_model = TransformerLayer(pretrained_path=config['pretrained_path'], both=True).to(device)\n",
        "    classifier = ATTClassifier(base_model.output_num(), class_num=2).to(device)\n",
        "    base_model.load_state_dict(torch.load(f\"./ckpts/best_basemodel_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\"))\n",
        "    classifier.load_state_dict(torch.load(f\"./ckpts/best_cls_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\"))\n",
        "    base_model = base_model.to(device)\n",
        "    classifier = classifier.to(device)\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    accuracies, all_outputs_pred, all_outputs_label = predict(base_model, classifier, loader1)\n",
        "    return accuracies, all_outputs_pred, all_outputs_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnYj2EAOZte_"
      },
      "outputs": [],
      "source": [
        "def plot_cf(cf_matrix):\n",
        "    ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "    ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "    ax.set_xlabel('\\nPredicted Values')\n",
        "    ax.set_ylabel('Actual Values ');\n",
        "    ## Ticket labels - List must be in alphabetical order\n",
        "    ax.xaxis.set_ticklabels(['False','True'])\n",
        "    ax.yaxis.set_ticklabels(['False','True'])\n",
        "    ## Display the visualization of the Confusion Matrix.\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "pS3ZHef_3-if",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ac4cf1-607f-4a76-84e8-857ee68946c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mckpts\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34mreports\u001b[0m/  \u001b[01;34mresults\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_arr = [1e-5,2e-5]\n",
        "batch_arr = [16,32,36,64]\n",
        "epoch_arr = [2,4]\n",
        "loss_arr=['FL']\n",
        "seed_arr=[298]"
      ],
      "metadata": {
        "id": "gHDHjV_d25sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/drive/MyDrive/iSarcasm/attn"
      ],
      "metadata": {
        "id": "jhoUa9AhHNEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/drive/MyDrive/iSarcasm/attn/m_298'"
      ],
      "metadata": {
        "id": "B5evIk3J8FS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# lr_arr = [2e-5]\n",
        "# batch_arr = [16]\n",
        "# epoch_arr = [2]\n",
        "# loss_arr=['FL']\n",
        "# seed_arr = [7774, 6911, 5751, 3723, 988, 2645, 3703, 2340, 298, 5423, 4759, 9054, 5495, 3120, 536, 16826, 3407 ]"
      ],
      "metadata": {
        "id": "J6Q7-A7FOMyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgfUDG6laoZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "86867d32e6ca440ca0b71bea26cdb1b5",
            "08327cfabc814cc5846fb8e089308787",
            "5b78f4d4c7744b64a47bb6c860d41ee8",
            "33a03e72165f43619496bcc7771d4366",
            "820b4a0fe3384ef083757c7fc8ec93c7",
            "066d3cfba8084ff8b1cb07fdde7e3f29",
            "4dfbfd413d044d82b4428c47f98d8c84",
            "be4b61100ddf4906b8d30c20733eddbb",
            "598a4b31b32040509f512758c05d4331",
            "f7c0f56bc1a5487299926431fa589b9f",
            "23e7843669454503bc9771ebd5df3282",
            "b0d02052dcd747bb87650458b4945509",
            "1efb06d13ae5497ab26c24292604c665",
            "965f6bcdaa9c46d5863c647cffe7bfaf",
            "72423e36ca954387bc3201a3eeffd9f0",
            "7db4e1a41abe44e2ac4c77bb779b6c21",
            "20da6d5c79fe4d2abc4412153c4ed323",
            "d8b001a8197242eea3a78d2b2f89ecc4",
            "2fab42f3dd5946e88a45d4519cdada14",
            "d741de45080645fc9148e29c6e65efe3",
            "0aa4089c9f8a4f4294c80ed77b8eea24",
            "f9aafd5b67ea4477a57e1e27a3711d2c",
            "f5ad0e1ad867467abd1e7eeb5088120a",
            "786d16583ac54720aa98f829d2d5fffc",
            "d011fc6794a74609b858bbad5a1ce4f5",
            "500c2acbd650464d8d489d3f901e4519",
            "31fcf63080274a9cb8ffa09918d1fb9c",
            "d2134ec5a3584ce9864d87f01e78efbf",
            "a9db3df7790a4c4fa83edec0cffee842",
            "409c2b82abd04b7cbb0ae938b969c634",
            "816b24eb6f604a99933b35a9bf297f77",
            "611190a21b7e4c4eb3723cb4cda9f0fd",
            "1371882921224c988d96f70cb5529368",
            "0c8aa597595b434ba2529a5a1a8c7136",
            "3fe0cd7ba4b64863b955347df15e4bdc",
            "0dbbccb39c524421a42c0e428f7fbd22",
            "4529088c68464c129150920fb0bd6f85",
            "566ca8ffa50544c0a48891801d858a36",
            "63aa809106794c909cbca234a9d5ba44",
            "888d319722fd405ea613bb183179670c",
            "3dd12246ccff442d84ff78f8fc0d371e",
            "5918be4ce3064024ac63249bdcad16cf",
            "b902374be2554bb7aef69390630c1f6c",
            "b1f7f611f4504133a1af45b25aa26e37",
            "82305f00ca4b4830b19324f48ad4fa80",
            "53a9dd1dbd4c474887afba1f706bc480",
            "07872cef7a2449779fc2c004db0a9766",
            "8d085c42452e44bdbeecd2adef411110",
            "15f57f21b69b48b899c7776d7a0cb904",
            "b89b756269ce4f62bef926d39c3ec2de",
            "06c9c9919f9747d9aa3398bdcc3a77c9",
            "554ba9c3de1c4537a4c0819661e12e1d",
            "5ff116e6c7dc48ecaf022a8d99ee2237",
            "794ffe4bf28349f193949f1410a3f43e",
            "1dc59ddf9f4241a1b3ef5c29ea4c63d1"
          ]
        },
        "outputId": "87e0e9e3-a45c-4362-cec6-ffe643ed1f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name 16_FL_1e-05_2_298\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86867d32e6ca440ca0b71bea26cdb1b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0d02052dcd747bb87650458b4945509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5ad0e1ad867467abd1e7eeb5088120a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c8aa597595b434ba2529a5a1a8c7136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82305f00ca4b4830b19324f48ad4fa80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 3.4s\n",
            "621/621: [===============================>] - ETA 0.0s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.1s\n",
            "model_name 16_FL_1e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.3s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.0s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.1s\n",
            "model_name 32_FL_1e-05_2_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 32_FL_1e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 36_FL_1e-05_2_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.5s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 36_FL_1e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.5s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 64_FL_1e-05_2_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "save model's checkpoint\n",
            "1400/1400: [==============================>.] - ETA 0.3s\n",
            "model_name 64_FL_1e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.3s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.3s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "save model's checkpoint\n",
            "1400/1400: [==============================>.] - ETA 0.3s\n",
            "model_name 16_FL_2e-05_2_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.3s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.1s\n",
            "model_name 16_FL_2e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.3s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.2s\n",
            "621/621: [===============================>] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.1s\n",
            "model_name 32_FL_2e-05_2_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 32_FL_2e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 36_FL_2e-05_2_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.5s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 36_FL_2e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.5s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "3077/3077: [===============================>] - ETA 0.4s\n",
            "621/621: [==============================>.] - ETA 0.1s\n",
            "save model's checkpoint\n",
            "1400/1400: [===============================>] - ETA 0.2s\n",
            "model_name 64_FL_2e-05_2_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.3s\n",
            "save model's checkpoint\n",
            "1400/1400: [==============================>.] - ETA 0.3s\n",
            "model_name 64_FL_2e-05_4_298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.3s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "3077/3077: [===============================>] - ETA 0.7s\n",
            "621/621: [============================>...] - ETA 0.2s\n",
            "save model's checkpoint\n",
            "1400/1400: [==============================>.] - ETA 0.3s\n"
          ]
        }
      ],
      "source": [
        "for lr_i in lr_arr:\n",
        "  for batch_i in batch_arr:\n",
        "    for epoch_i in epoch_arr:\n",
        "      for loss_i in loss_arr:\n",
        "        for seed_i in seed_arr:\n",
        "\n",
        "            args = {}\n",
        "            args['lr_mult'] = 1.0\n",
        "            args['seed'] = seed_i\n",
        "            args['num_worker'] = 4\n",
        "            args['lang'] = 'ar'\n",
        "            args['phase'] = 'train'\n",
        "            args['lm_pretrained'] = 'marbert'\n",
        "\n",
        "            args['lr'] =lr_i\n",
        "            args['epochs'] = epoch_i\n",
        "            args['batch_size'] = batch_i\n",
        "            args['loss'] = loss_i\n",
        "            config = {}\n",
        "            config[\"max_length\"] = 64\n",
        "            config['args'] = args\n",
        "            config[\"output_for_test\"] = True\n",
        "            config['epochs'] = args['epochs']\n",
        "            config[\"class_num\"] = 1\n",
        "            config[\"lr\"] = args['lr']\n",
        "            config['lr_mult'] = args['lr_mult']\n",
        "            config['batch_size'] = args['batch_size']\n",
        "            config['lm'] = args['lm_pretrained']\n",
        "            config['loss'] = args['loss']\n",
        "            lang = args['lang']\n",
        "            dosegmentation = False\n",
        "\n",
        "\n",
        "            if args['lm_pretrained'] == 'marbert':\n",
        "                config['pretrained_path'] = \"UBC-NLP/MARBERT\"\n",
        "\n",
        "\n",
        "            RANDOM_SEED = config['args']['seed']\n",
        "\n",
        "            random.seed(RANDOM_SEED)\n",
        "            np.random.seed(RANDOM_SEED)\n",
        "            torch.manual_seed(RANDOM_SEED)\n",
        "            torch.cuda.manual_seed(RANDOM_SEED)\n",
        "            torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "            model_name = f\"{config['args']['batch_size']}_{config['args']['loss']}_{config['args']['lr']}_{config['args']['epochs']}_{config['args']['seed']}\"\n",
        "            print('model_name', model_name)\n",
        "            train_loader, valid_loader = loadTrainValData2(size = 0.2 ,batchsize=args['batch_size'], num_worker=0, pretraine_path=config['pretrained_path'], max_length=config['max_length'])\n",
        "            best_val_accuracy, best_val_f1_score, best_val_f1_sarcastic, best_val_loss, best_epo =train_full(config, train_loader, valid_loader)\n",
        "\n",
        "\n",
        "            results = {'model_name' : f'{model_name}'}\n",
        "            results['loss_fn']= config['args']['loss']\n",
        "            results['batch_size']=config['args']['batch_size']\n",
        "            results['lr']=config['args']['lr']\n",
        "            results['f1_sarcastic'] = best_val_f1_sarcastic\n",
        "            results['f1_score'] = best_val_f1_score\n",
        "            results['epoch']=config['args']['epochs']\n",
        "            results['seed']=config['args']['seed']\n",
        "\n",
        "\n",
        "            with open(results_h, 'a+') as f:\n",
        "                  f.write(json.dumps(results) + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "            args['phase'] = 'predict'\n",
        "            config['args'] = args\n",
        "\n",
        "            test_loader = loadTestData(batchsize=args['batch_size'], num_worker=0, pretraine_path=config['pretrained_path'],  max_length=config['max_length'])\n",
        "            test_accuracies, test_all_outputs, test_all_labels = eval_full(config, loader1=test_loader)\n",
        "\n",
        "            results = {'model_name' : f'{model_name}'}\n",
        "            results['loss_fn']= config['args']['loss']\n",
        "            results['batch_size']=config['args']['batch_size']\n",
        "            results['lr']=config['args']['lr']\n",
        "            results['f1_sarcastic'] = test_accuracies['f1_sarcastic']\n",
        "            results['f1_score'] = test_accuracies['f1_score']\n",
        "            results['epoch']=config['args']['epochs']\n",
        "            results['seed']=config['args']['seed']\n",
        "            with open(results_t, 'a+') as f:\n",
        "                  f.write(json.dumps(results) + '\\n')\n",
        "            base_file=f\"best_basemodel_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\"\n",
        "            cls_file=f\"best_cls_sarcasm_{config['batch_size']}_{config['loss']}_{config['lr']}_ml{config['max_length']}_{config['epochs']}_{config['args']['seed']}_sarcat.pth\"\n",
        "\n",
        "            shutil.copy(f\"./ckpts/{base_file}\", f\"/content/drive/MyDrive/iSarcasm/attn/m_298/{base_file}\")\n",
        "            shutil.copy(f\"./ckpts/{cls_file}\", f\"/content/drive/MyDrive/iSarcasm/attn/m_298/{cls_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_db_h = pd.read_json(results_h, lines=True)\n",
        "print(\"results_db_h\", results_db_h)"
      ],
      "metadata": {
        "id": "psKTD5MklW7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453401df-58cc-4b5c-ff04-a10240ae6914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results_db_h            model_name loss_fn  batch_size       lr  f1_sarcastic  f1_score  \\\n",
            "0   16_FL_1e-05_2_298      FL          16  0.00001      0.724409  0.826780   \n",
            "1   16_FL_1e-05_4_298      FL          16  0.00001      0.747170  0.839296   \n",
            "2   32_FL_1e-05_2_298      FL          32  0.00001      0.720000  0.824718   \n",
            "3   32_FL_1e-05_4_298      FL          32  0.00001      0.714859  0.821679   \n",
            "4   36_FL_1e-05_2_298      FL          36  0.00001      0.714286  0.820779   \n",
            "5   36_FL_1e-05_4_298      FL          36  0.00001      0.732283  0.831729   \n",
            "6   64_FL_1e-05_2_298      FL          64  0.00001      0.611354  0.761748   \n",
            "7   64_FL_1e-05_4_298      FL          64  0.00001      0.725869  0.826820   \n",
            "8   16_FL_2e-05_2_298      FL          16  0.00002      0.728682  0.828772   \n",
            "9   16_FL_2e-05_4_298      FL          16  0.00002      0.735632  0.832648   \n",
            "10  32_FL_2e-05_2_298      FL          32  0.00002      0.716535  0.821830   \n",
            "11  32_FL_2e-05_4_298      FL          32  0.00002      0.726562  0.827784   \n",
            "12  36_FL_2e-05_2_298      FL          36  0.00002      0.728682  0.828772   \n",
            "13  36_FL_2e-05_4_298      FL          36  0.00002      0.736434  0.833664   \n",
            "14  64_FL_2e-05_2_298      FL          64  0.00002      0.711462  0.818825   \n",
            "15  64_FL_2e-05_4_298      FL          64  0.00002      0.731518  0.830733   \n",
            "\n",
            "    epoch  seed  \n",
            "0       2   298  \n",
            "1       4   298  \n",
            "2       2   298  \n",
            "3       4   298  \n",
            "4       2   298  \n",
            "5       4   298  \n",
            "6       2   298  \n",
            "7       4   298  \n",
            "8       2   298  \n",
            "9       4   298  \n",
            "10      2   298  \n",
            "11      4   298  \n",
            "12      2   298  \n",
            "13      4   298  \n",
            "14      2   298  \n",
            "15      4   298  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_db_t = pd.read_json(results_t, lines=True)\n",
        "print(\"results_db_t\", results_db_t)"
      ],
      "metadata": {
        "id": "wL78BfKURMOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd705d8-e157-4595-9569-d06760974b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results_db_t            model_name loss_fn  batch_size       lr  f1_sarcastic  f1_score  \\\n",
            "0   16_FL_1e-05_2_298      FL          16  0.00001      0.670051  0.808010   \n",
            "1   16_FL_1e-05_4_298      FL          16  0.00001      0.642534  0.787764   \n",
            "2   32_FL_1e-05_2_298      FL          32  0.00001      0.679045  0.814553   \n",
            "3   32_FL_1e-05_4_298      FL          32  0.00001      0.663212  0.804680   \n",
            "4   36_FL_1e-05_2_298      FL          36  0.00001      0.682927  0.817399   \n",
            "5   36_FL_1e-05_4_298      FL          36  0.00001      0.673418  0.809890   \n",
            "6   64_FL_1e-05_2_298      FL          64  0.00001      0.591045  0.767733   \n",
            "7   64_FL_1e-05_4_298      FL          64  0.00001      0.673317  0.809355   \n",
            "8   16_FL_2e-05_2_298      FL          16  0.00002      0.638095  0.787115   \n",
            "9   16_FL_2e-05_4_298      FL          16  0.00002      0.608889  0.766998   \n",
            "10  32_FL_2e-05_2_298      FL          32  0.00002      0.704663  0.828719   \n",
            "11  32_FL_2e-05_4_298      FL          32  0.00002      0.671717  0.808820   \n",
            "12  36_FL_2e-05_2_298      FL          36  0.00002      0.700000  0.826446   \n",
            "13  36_FL_2e-05_4_298      FL          36  0.00002      0.655502  0.797524   \n",
            "14  64_FL_2e-05_2_298      FL          64  0.00002      0.673629  0.810956   \n",
            "15  64_FL_2e-05_4_298      FL          64  0.00002      0.660333  0.800112   \n",
            "\n",
            "    epoch  seed  \n",
            "0       2   298  \n",
            "1       4   298  \n",
            "2       2   298  \n",
            "3       4   298  \n",
            "4       2   298  \n",
            "5       4   298  \n",
            "6       2   298  \n",
            "7       4   298  \n",
            "8       2   298  \n",
            "9       4   298  \n",
            "10      2   298  \n",
            "11      4   298  \n",
            "12      2   298  \n",
            "13      4   298  \n",
            "14      2   298  \n",
            "15      4   298  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/iSarcasm/attn/m_298/results'"
      ],
      "metadata": {
        "id": "xYKLemhDerFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caefbd1a-ae4c-4dcd-931f-a487ff8f423e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_f.jsonl  results_h.jsonl  results_t.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"results_h.jsonl\", \"/content/drive/MyDrive/iSarcasm/attn/m_298/results/results_h.jsonl\")\n",
        "shutil.copy(\"results_t.jsonl\", \"/content/drive/MyDrive/iSarcasm/attn/m_298/results/results_t.jsonl\")\n",
        "# shutil.copy(\"best_model_f.jsonl\", \"/content/drive/MyDrive/iSarcasm/attn/m_298/results/best_model_f.jsonl\")"
      ],
      "metadata": {
        "id": "ZXLV_a8QYZW_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "87d40f75-a8be-4093-eb38-cbb417648dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/iSarcasm/attn/m_298/results/results_t.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator"
      ],
      "metadata": {
        "id": "eu5UPvVS6xQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_h = '/content/drive/MyDrive/iSarcasm/attn/m_298/results/results_h.jsonl'\n",
        "results_t = '/content/drive/MyDrive/iSarcasm/attn/m_298/results/results_t.jsonl'\n",
        "best_model_f = \"/content/drive/MyDrive/iSarcasm/attn/m_298/results/best_model_f.jsonl\"\n",
        "\n",
        "if os.path.exists(best_model_f):\n",
        "    os.remove(best_model_f)\n",
        "\n",
        "results_db_h = pd.read_json(results_h, lines=True)\n",
        "results_db_t = pd.read_json(results_t, lines=True)\n",
        "\n",
        "individual_model_val_accs_h = {}\n",
        "for _, row in results_db_h.iterrows():\n",
        "    individual_model_val_accs_h[row['model_name']] = row['f1_score']\n",
        "\n",
        "individual_model_val_accs_h = sorted(individual_model_val_accs_h.items(), key=operator.itemgetter(1))\n",
        "individual_model_val_accs_h.reverse()\n",
        "sorted_models = [x[0] for x in individual_model_val_accs_h]\n",
        "\n",
        "\n",
        "\n",
        "for _, row in results_db_t.iterrows():\n",
        "    if row['model_name'] == sorted_models[0]:\n",
        "       row_t = row\n",
        "       break\n",
        "\n",
        "results = {'best_model' : f'{sorted_models[0]}'}\n",
        "\n",
        "results['loss_fn']= row_t['loss_fn']\n",
        "results['batch_size']=row_t['batch_size']\n",
        "results['lr']=row_t['lr']\n",
        "results['epoch']=row_t['epoch']\n",
        "results['seed']=row_t['seed']\n",
        "results['f1_sarcastic'] = row_t['f1_sarcastic']\n",
        "results['f1_score'] = row_t['f1_score']\n",
        "\n",
        "with open(best_model_f, 'a+') as f:\n",
        "         f.write(json.dumps(results) + '\\n')\n"
      ],
      "metadata": {
        "id": "qHoyDlknz1Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_db_t = pd.read_json(best_model_f, lines=True)\n",
        "print(\"best_model_db_t\", best_model_db_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7Cs-O9f5jEg",
        "outputId": "b7c32550-8cd7-4404-e66e-981d02c8df7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_db_t           best_model loss_fn  batch_size       lr  epoch  seed  f1_sarcastic  \\\n",
            "0  16_FL_1e-05_4_298      FL          16  0.00001      4   298      0.642534   \n",
            "\n",
            "   f1_score  \n",
            "0  0.787764  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "guJiGSoy6_tY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "86867d32e6ca440ca0b71bea26cdb1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08327cfabc814cc5846fb8e089308787",
              "IPY_MODEL_5b78f4d4c7744b64a47bb6c860d41ee8",
              "IPY_MODEL_33a03e72165f43619496bcc7771d4366"
            ],
            "layout": "IPY_MODEL_820b4a0fe3384ef083757c7fc8ec93c7"
          }
        },
        "08327cfabc814cc5846fb8e089308787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066d3cfba8084ff8b1cb07fdde7e3f29",
            "placeholder": "​",
            "style": "IPY_MODEL_4dfbfd413d044d82b4428c47f98d8c84",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "5b78f4d4c7744b64a47bb6c860d41ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4b61100ddf4906b8d30c20733eddbb",
            "max": 376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_598a4b31b32040509f512758c05d4331",
            "value": 376
          }
        },
        "33a03e72165f43619496bcc7771d4366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c0f56bc1a5487299926431fa589b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_23e7843669454503bc9771ebd5df3282",
            "value": " 376/376 [00:00&lt;00:00, 16.3kB/s]"
          }
        },
        "820b4a0fe3384ef083757c7fc8ec93c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066d3cfba8084ff8b1cb07fdde7e3f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfbfd413d044d82b4428c47f98d8c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be4b61100ddf4906b8d30c20733eddbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598a4b31b32040509f512758c05d4331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7c0f56bc1a5487299926431fa589b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23e7843669454503bc9771ebd5df3282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0d02052dcd747bb87650458b4945509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1efb06d13ae5497ab26c24292604c665",
              "IPY_MODEL_965f6bcdaa9c46d5863c647cffe7bfaf",
              "IPY_MODEL_72423e36ca954387bc3201a3eeffd9f0"
            ],
            "layout": "IPY_MODEL_7db4e1a41abe44e2ac4c77bb779b6c21"
          }
        },
        "1efb06d13ae5497ab26c24292604c665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20da6d5c79fe4d2abc4412153c4ed323",
            "placeholder": "​",
            "style": "IPY_MODEL_d8b001a8197242eea3a78d2b2f89ecc4",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "965f6bcdaa9c46d5863c647cffe7bfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fab42f3dd5946e88a45d4519cdada14",
            "max": 701,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d741de45080645fc9148e29c6e65efe3",
            "value": 701
          }
        },
        "72423e36ca954387bc3201a3eeffd9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa4089c9f8a4f4294c80ed77b8eea24",
            "placeholder": "​",
            "style": "IPY_MODEL_f9aafd5b67ea4477a57e1e27a3711d2c",
            "value": " 701/701 [00:00&lt;00:00, 49.0kB/s]"
          }
        },
        "7db4e1a41abe44e2ac4c77bb779b6c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20da6d5c79fe4d2abc4412153c4ed323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b001a8197242eea3a78d2b2f89ecc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fab42f3dd5946e88a45d4519cdada14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d741de45080645fc9148e29c6e65efe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0aa4089c9f8a4f4294c80ed77b8eea24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9aafd5b67ea4477a57e1e27a3711d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5ad0e1ad867467abd1e7eeb5088120a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_786d16583ac54720aa98f829d2d5fffc",
              "IPY_MODEL_d011fc6794a74609b858bbad5a1ce4f5",
              "IPY_MODEL_500c2acbd650464d8d489d3f901e4519"
            ],
            "layout": "IPY_MODEL_31fcf63080274a9cb8ffa09918d1fb9c"
          }
        },
        "786d16583ac54720aa98f829d2d5fffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2134ec5a3584ce9864d87f01e78efbf",
            "placeholder": "​",
            "style": "IPY_MODEL_a9db3df7790a4c4fa83edec0cffee842",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "d011fc6794a74609b858bbad5a1ce4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409c2b82abd04b7cbb0ae938b969c634",
            "max": 1099714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_816b24eb6f604a99933b35a9bf297f77",
            "value": 1099714
          }
        },
        "500c2acbd650464d8d489d3f901e4519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_611190a21b7e4c4eb3723cb4cda9f0fd",
            "placeholder": "​",
            "style": "IPY_MODEL_1371882921224c988d96f70cb5529368",
            "value": " 1.10M/1.10M [00:00&lt;00:00, 3.37MB/s]"
          }
        },
        "31fcf63080274a9cb8ffa09918d1fb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2134ec5a3584ce9864d87f01e78efbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9db3df7790a4c4fa83edec0cffee842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "409c2b82abd04b7cbb0ae938b969c634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816b24eb6f604a99933b35a9bf297f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "611190a21b7e4c4eb3723cb4cda9f0fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1371882921224c988d96f70cb5529368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c8aa597595b434ba2529a5a1a8c7136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe0cd7ba4b64863b955347df15e4bdc",
              "IPY_MODEL_0dbbccb39c524421a42c0e428f7fbd22",
              "IPY_MODEL_4529088c68464c129150920fb0bd6f85"
            ],
            "layout": "IPY_MODEL_566ca8ffa50544c0a48891801d858a36"
          }
        },
        "3fe0cd7ba4b64863b955347df15e4bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63aa809106794c909cbca234a9d5ba44",
            "placeholder": "​",
            "style": "IPY_MODEL_888d319722fd405ea613bb183179670c",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "0dbbccb39c524421a42c0e428f7fbd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd12246ccff442d84ff78f8fc0d371e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5918be4ce3064024ac63249bdcad16cf",
            "value": 112
          }
        },
        "4529088c68464c129150920fb0bd6f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b902374be2554bb7aef69390630c1f6c",
            "placeholder": "​",
            "style": "IPY_MODEL_b1f7f611f4504133a1af45b25aa26e37",
            "value": " 112/112 [00:00&lt;00:00, 8.32kB/s]"
          }
        },
        "566ca8ffa50544c0a48891801d858a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63aa809106794c909cbca234a9d5ba44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888d319722fd405ea613bb183179670c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd12246ccff442d84ff78f8fc0d371e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5918be4ce3064024ac63249bdcad16cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b902374be2554bb7aef69390630c1f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1f7f611f4504133a1af45b25aa26e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82305f00ca4b4830b19324f48ad4fa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53a9dd1dbd4c474887afba1f706bc480",
              "IPY_MODEL_07872cef7a2449779fc2c004db0a9766",
              "IPY_MODEL_8d085c42452e44bdbeecd2adef411110"
            ],
            "layout": "IPY_MODEL_15f57f21b69b48b899c7776d7a0cb904"
          }
        },
        "53a9dd1dbd4c474887afba1f706bc480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89b756269ce4f62bef926d39c3ec2de",
            "placeholder": "​",
            "style": "IPY_MODEL_06c9c9919f9747d9aa3398bdcc3a77c9",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "07872cef7a2449779fc2c004db0a9766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554ba9c3de1c4537a4c0819661e12e1d",
            "max": 654186400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ff116e6c7dc48ecaf022a8d99ee2237",
            "value": 654186400
          }
        },
        "8d085c42452e44bdbeecd2adef411110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_794ffe4bf28349f193949f1410a3f43e",
            "placeholder": "​",
            "style": "IPY_MODEL_1dc59ddf9f4241a1b3ef5c29ea4c63d1",
            "value": " 654M/654M [00:05&lt;00:00, 156MB/s]"
          }
        },
        "15f57f21b69b48b899c7776d7a0cb904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b89b756269ce4f62bef926d39c3ec2de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c9c9919f9747d9aa3398bdcc3a77c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "554ba9c3de1c4537a4c0819661e12e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff116e6c7dc48ecaf022a8d99ee2237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "794ffe4bf28349f193949f1410a3f43e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dc59ddf9f4241a1b3ef5c29ea4c63d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}